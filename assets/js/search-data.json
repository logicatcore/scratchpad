{
  
    
        "post0": {
            "title": "Overview",
            "content": "&gt; Generating a Gaussian matrix for applying Gaussian Blur to an Image - toc: false - branch: master - badges: true - comments: true - categories: [Camera, Computer-Vision] - image: images/gaussian_blur/gaussian_blur_cover1.png - search_exclude: false . %matplotlib widget import numpy as np from matplotlib import cm import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D . def GM(std_dev, size): &quot;&quot;&quot; Computes a gaussian matrix/kernel of given size :param std_dev: Standard deviation of the Gaussian :param size: Size of kernel needed &quot;&quot;&quot; if (size % 2 != 1): print(&quot;Size has to be odd&quot;) return # Gaussian parameters and normalizing constant sigma = std_dev # Variance var = sigma **2 # Normalisation parameter (is constant for all matrix entries) norm = 1/(np.sqrt(2*np.pi)*sigma) def density(x): return norm * np.exp(-0.5*(x)**2/var) # quarter kernel size qs = (size//2) + 1 # quarter kernel qk = np.zeros((qs, qs)) for R in range(qs): for C in range(qs): qk[R,C] = density(2*qs - (R+C)) # mirror the kernel verticaly and horizontaly kernel = np.hstack((qk, np.flip(qk,1)[:,1:])) kernel = np.vstack((kernel, np.flip(kernel,0)[1:,:])) # normalise the weights kernel = kernel / np.sum(kernel) return kernel . Generating and visualising . kernel_size = 41 . idxs = np.indices((kernel_size, kernel_size)) . fig = plt.figure(figsize=(10,4)) std_devs = [14, 10, 6] for i, std in enumerate(std_devs): fig_idx = 100 + len(std_devs)*10 + 1 + i gaussiann_kernel = GM(std, kernel_size) ax = fig.add_subplot(fig_idx, projection=&#39;3d&#39;) # ax.scatter(idxs[0].reshape(-1), idxs[1].reshape(-1), gaussiann_kernel.reshape(-1)) ax.plot_surface(idxs[0], idxs[1], gaussiann_kernel, cmap=cm.coolwarm) ax.set_title(f&quot;Standard deviation = {std}&quot;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_zlabel(&#39;z&#39;) . . References .",
            "url": "https://logicatcore.github.io/scratchpad/2021/07/07/Gaussian-Blur-Matrix.html",
            "relUrl": "/2021/07/07/Gaussian-Blur-Matrix.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "3D Oriented bounding boxes made simple",
            "content": "Overview . In the previous post we looked at the process of generating a 2D bounding box around some data/cluster of points. But while working with LIDARs i.e. point cloud data respectively, we would want the bounding boxes to be in 3-dimensions just like the data. . 2D Oriented bounding boxes recap . As a quick recap, the steps involved in generating 2D oriented box is as follows- . Translate the data to match the means to the origin | Calculate the Eigen-vectors | Find the inclination/orientation angle of the principal component i.e. the Eigen-vector with highes Eigen-value | Use the angle calculated in step 3 to align the data/Eigen-vectors to the cartesian basis vectors | Calculate the bounding box by determining the max, min values along each dimension | Undo the rotation and translation to both data and bounding box coordinates | Notes on difference in procedure to 3D oriented bounding boxes . Here we notice that Eigen-vectors, translation, and rotation tasks play the main role. Calculating Eigen-vectors and performing translation is a straight forward task in 3D also but rotation is not. As, rotation around orthogonal axis is not commutative i.e. the order in which the layers of a Rubiks cube are rotated matters. That is changing the order in which the layers are rotated will result in a completely different colour patterns on the Rubiks cube. This non-commutative nature of rotations is shown below (feel free to skip to the next section if you are already aware of this) . Handle some imports and set seed for the random generator . %matplotlib widget import matplotlib.pyplot as plt import numpy as np import numpy.linalg as LA from mpl_toolkits.mplot3d import Axes3D . Roll, Pitch, and Yaw matrices . Here we define the yaw(rotation about z axis), pitch(rotation about y axis), and roll(rotation about x axis) matrices to see the effects of rotating a vector (2, 0, 0) and prove that rotations are not commutative in nature. . def yaw(theta): theta = np.deg2rad(theta) return np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0], [ 0, 0, 1]]) def pitch(theta): theta = np.deg2rad(theta) return np.array([[np.cos(theta) , 0, np.sin(theta)], [ 0, 1, 0], [-np.sin(theta), 0, np.cos(theta)]]) def roll(theta): theta = np.deg2rad(theta) return np.array([[1, 0, 0], [0, np.cos(theta), np.sin(theta)], [0, -np.sin(theta), np.cos(theta)]]) . def CreateFigure(): &quot;&quot;&quot; Helper function to create figures and label axes &quot;&quot;&quot; fig = plt.figure() ax = fig.add_subplot(111, projection=&#39;3d&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_zlabel(&#39;z&#39;) return ax . Yaw . Rotate vector (2, 0, 0) by 90 degrees anti-clockwise around z axis . x = np.matmul(yaw(90), np.array([[2], [0], [0]])) . ax = CreateFigure() ax.plot([0, 2], [0, 0], [0, 0], label=&quot;before rotation&quot;) ax.plot([0, x[0,0]], [0, x[1,0]], [0, x[2,0]], label=&quot;after rotation&quot;) ax.plot(2 * np.cos(np.linspace(0, np.pi/2, 50)), 2 * np.sin(np.linspace(0, np.pi/2, 50)), 0, linestyle=&quot;dashed&quot;, label=&quot;rotation trail&quot;) ax.legend() . . Roll . Rotate vector (2, 0, 0) by 90 degrees anti-clockwise around x axis . x = np.matmul(roll(90), np.array([[0], [2], [0]])) . ax = CreateFigure() ax.plot([0, 0], [0, 2], [0, 0], label=&quot;before rotation&quot;) ax.plot([0, x[0,0]], [0, x[1,0]], [0, x[2,0]], label=&quot;after rotation&quot;) ax.plot(np.zeros(50), 2 * np.cos(np.linspace(0, np.pi/2, 50)), -2 * np.sin(np.linspace(0, np.pi/2, 50)), linestyle=&quot;dashed&quot;, label=&quot;rotation trail&quot;) ax.legend() . . Pitch . Rotate point (2, 0) by 90 degrees anti-clockwise around y axis . x = np.matmul(pitch(90), np.array([[2], [0], [0]])) . ax = CreateFigure() ax.plot([0, 2], [0, 0], [0, 0], label=&quot;before rotation&quot;) ax.plot([0, x[0,0]], [0, x[1,0]], [0, x[2,0]], label=&quot;after rotation&quot;) ax.plot(2 * np.cos(np.linspace(0, np.pi/2, 50)), np.zeros(50), -2 * np.sin(np.linspace(0, np.pi/2, 50)), linestyle=&quot;dashed&quot;, label=&quot;rotation trail&quot;) ax.legend() . . Roll, Pitch, and Yaw together and the non-commutative nature of rotations visualised . basis = np.array([[1,0,0], [0,1,0], [0,0,1]]) x1 = np.matmul(yaw(90) @ pitch(90), np.array([[2], [0], [0]])) x2 = np.matmul(pitch(90) @ yaw(90), np.array([[2], [0], [0]])) . def SetAxisProp(ax): ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_zlabel(&#39;z&#39;) ax.set_xlim(-2, 2) ax.set_ylim(-2, 2) ax.set_zlim(-2, 2) fig = plt.figure(figsize=(10,6)) ax1 = fig.add_subplot(121, projection=&#39;3d&#39;) SetAxisProp(ax1) ax2 = fig.add_subplot(122, projection=&#39;3d&#39;) SetAxisProp(ax2) ax1.set_title(&quot;Yaw x Pitch&quot;) ax1.plot([0, 2], [0, 0], [0, 0], label=&quot;before rotation&quot;) ax1.plot([0, x1[0,0]], [0, x1[1,0]], [0, x1[2,0]], label=&quot;after rotation&quot;) ax1.legend() ax2.set_title(&quot;Pitch x Yaw&quot;) ax2.plot([0, 2], [0, 0], [0, 0], label=&quot;before rotation&quot;) ax2.plot([0, x2[0,0]], [0, x2[1,0]], [0, x2[2,0]], label=&quot;after rotation&quot;) ax2.legend() . . As we can see in the figure above, just changing the order in which yaw and pitch the vector, the resulting vector is completely different! . So, in this post the main difference compared to the previous post involving 2D oriented bounding boxes would be concerned with rotation and the way we align the data to the cartesian basis. . A quick overiew of what is to come . . Let us get started with the code and the math to generate a bounding box . Generate 3D sample data and visualise it . x = np.linspace(3, 8, 100) + np.random.normal(0, 0.2, 100) y = np.linspace(3, 8, 100) + np.random.normal(0, 0.2, 100) z = np.linspace(1, 3, 100) + np.random.normal(0, 0.2, 100) data = np.vstack([x, y, z]) fig = plt.figure() ax = fig.add_subplot(111, projection=&#39;3d&#39;) ax.scatter(data[0,:], data[1,:], data[2,:], label=&quot;original data&quot;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_zlabel(&#39;z&#39;) ax.legend() . . Calculate means, covariance matrix, eigen values, and eigen vectors for the rotated data . means = np.mean(data, axis=1) cov = np.cov(data) eval, evec = LA.eig(cov) eval, evec . (array([4.74618325, 0.0445827 , 0.03395297]), array([[-0.68725458, -0.52695506, -0.4999995 ], [-0.67558502, 0.71661269, 0.1733526 ], [-0.26695696, -0.45692954, 0.84849831]])) . Check angle between eigen vectors . Since the Eigen-vectors returned by LA.eig are pre normalised, we can determine the angle between the eigen vectors using the dot product . np.rad2deg(np.arccos(np.dot(evec[:,0], evec[:,1]))) . 89.99999999999997 . np.rad2deg(np.arccos(np.dot(evec[:,1], evec[:,2]))) . 89.99999999999976 . np.rad2deg(np.arccos(np.dot(evec[:,2], evec[:,0]))) . 90.0 . Translate the data . centered_data = data - means[:,np.newaxis] . fig = plt.figure() ax = fig.add_subplot(111, projection=&#39;3d&#39;) ax.scatter(data[0,:], data[1,:], data[2,:], label=&quot;original data&quot;) ax.scatter(centered_data[0,:], centered_data[1,:], centered_data[2,:], label=&quot;centered data&quot;) ax.legend() # cartesian basis ax.plot([0, 1], [0, 0], [0, 0], color=&#39;b&#39;, linewidth=4) ax.plot([0, 0], [0, 1], [0, 0], color=&#39;b&#39;, linewidth=4) ax.plot([0, 0], [0, 0], [0, 1], color=&#39;b&#39;, linewidth=4) # eigen basis ax.plot([0, evec[0, 0]], [0, evec[1, 0]], [0, evec[2, 0]], color=&#39;r&#39;, linewidth=4) ax.plot([0, evec[0, 1]], [0, evec[1, 1]], [0, evec[2, 1]], color=&#39;g&#39;, linewidth=4) ax.plot([0, evec[0, 2]], [0, evec[1, 2]], [0, evec[2, 2]], color=&#39;k&#39;, linewidth=4) . . The axis orthogonal axes in blue are the cartesian basis and the ones in red, green, and black are the orthogonal eigen vector . Simple max and min based bounding box . def draw3DRectangle(ax, x1, y1, z1, x2, y2, z2): # the Translate the datatwo sets of coordinates form the apposite diagonal points of a cuboid ax.plot([x1, x2], [y1, y1], [z1, z1], color=&#39;b&#39;) # | (up) ax.plot([x2, x2], [y1, y2], [z1, z1], color=&#39;b&#39;) # --&gt; ax.plot([x2, x1], [y2, y2], [z1, z1], color=&#39;b&#39;) # | (down) ax.plot([x1, x1], [y2, y1], [z1, z1], color=&#39;b&#39;) # &lt;-- ax.plot([x1, x2], [y1, y1], [z2, z2], color=&#39;b&#39;) # | (up) ax.plot([x2, x2], [y1, y2], [z2, z2], color=&#39;b&#39;) # --&gt; ax.plot([x2, x1], [y2, y2], [z2, z2], color=&#39;b&#39;) # | (down) ax.plot([x1, x1], [y2, y1], [z2, z2], color=&#39;b&#39;) # &lt;-- ax.plot([x1, x1], [y1, y1], [z1, z2], color=&#39;b&#39;) # | (up) ax.plot([x2, x2], [y2, y2], [z1, z2], color=&#39;b&#39;) # --&gt; ax.plot([x1, x1], [y2, y2], [z1, z2], color=&#39;b&#39;) # | (down) ax.plot([x2, x2], [y1, y1], [z1, z2], color=&#39;b&#39;) # &lt;-- . Compute the minimums and maximums of each dimension and draw the rectangle . xmin, xmax, ymin, ymax, zmin, zmax = np.min(centered_data[0, :]), np.max(centered_data[0, :]), np.min(centered_data[1, :]), np.max(centered_data[1, :]), np.min(centered_data[2, :]), np.max(centered_data[2, :]) # Code repeat start fig = plt.figure() ax = fig.add_subplot(111, projection=&#39;3d&#39;) ax.scatter(data[0,:], data[1,:], data[2,:], label=&quot;original data&quot;) ax.scatter(centered_data[0,:], centered_data[1,:], centered_data[2,:], label=&quot;centered data&quot;) ax.legend() # cartesian basis ax.plot([0, 1], [0, 0], [0, 0], color=&#39;b&#39;, linewidth=4) ax.plot([0, 0], [0, 1], [0, 0], color=&#39;b&#39;, linewidth=4) ax.plot([0, 0], [0, 0], [0, 1], color=&#39;b&#39;, linewidth=4) # eigen basis ax.plot([0, evec[0, 0]], [0, evec[1, 0]], [0, evec[2, 0]], color=&#39;r&#39;, linewidth=4) ax.plot([0, evec[0, 1]], [0, evec[1, 1]], [0, evec[2, 1]], color=&#39;g&#39;, linewidth=4) ax.plot([0, evec[0, 2]], [0, evec[1, 2]], [0, evec[2, 2]], color=&#39;k&#39;, linewidth=4) # Code repeat end draw3DRectangle(ax, xmin, ymin, zmin, xmax, ymax, zmax) . . Rotation! the crux of the process in generating the oriented bounding box . As previously mentioned that the Eigen-vectors are pre normalised and that they are orthogonal to each other when we checked the angles between them, in effect we have in our hands a new set of basis vectors. We can use this basis vector to transform coordinates to and fro defined using any other basis vectors. . That is, in our case the Eigen-vectors matrix evec can be used to transform coordinates defined in the basis vectors (1,0,0), (0,1,0), (0,0,1). Let us denote the coordinates in the cartesian basis vectors as C and the coordinates with Eigen-vectors as basis as E. . We can transform coordinated from C to E by multiplying with the evec basis vector matrix | We can transform coordinated from E to C by multiplying with the inverse(evec) basis vector matrix | . Since the Eigen-vectors are normalised, the inverse(evec) == transpose(evec) (the code below proves this) . np.allclose(LA.inv(evec), evec.T) . True . Rotate the data i.e. align the eigen vector to the cartesian basis . aligned_coords = np.matmul(evec.T, centered_data) . fig = plt.figure() ax = fig.add_subplot(111, projection=&#39;3d&#39;) ax.scatter(aligned_coords[0,:], aligned_coords[1,:], aligned_coords[2,:], color=&#39;g&#39;, label=&quot;rotated/aligned data&quot;) ax.scatter(centered_data[0,:], centered_data[1,:], centered_data[2,:], color=&#39;orange&#39;, label=&quot;centered data&quot;) ax.legend() ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_zlabel(&#39;z&#39;) . . Compute the minimums and maximums of each dimension and draw the rectangle . xmin, xmax, ymin, ymax, zmin, zmax = np.min(aligned_coords[0, :]), np.max(aligned_coords[0, :]), np.min(aligned_coords[1, :]), np.max(aligned_coords[1, :]), np.min(aligned_coords[2, :]), np.max(aligned_coords[2, :]) fig = plt.figure() ax = fig.add_subplot(111, projection=&#39;3d&#39;) ax.scatter(aligned_coords[0,:], aligned_coords[1,:], aligned_coords[2,:], color=&#39;g&#39;, label=&quot;rotated/aligned data&quot;) ax.scatter(centered_data[0,:], centered_data[1,:], centered_data[2,:], color=&#39;tab:orange&#39;, label=&quot;centered data&quot;) ax.legend() ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_zlabel(&#39;z&#39;) # cartesian basis ax.plot([0, 1], [0, 0], [0, 0], color=&#39;b&#39;, linewidth=4) ax.plot([0, 0], [0, 1], [0, 0], color=&#39;b&#39;, linewidth=4) ax.plot([0, 0], [0, 0], [0, 1], color=&#39;b&#39;, linewidth=4) # eigen basis ax.plot([0, evec[0, 0]], [0, evec[1, 0]], [0, evec[2, 0]], color=&#39;r&#39;, linewidth=4) ax.plot([0, evec[0, 1]], [0, evec[1, 1]], [0, evec[2, 1]], color=&#39;g&#39;, linewidth=4) ax.plot([0, evec[0, 2]], [0, evec[1, 2]], [0, evec[2, 2]], color=&#39;k&#39;, linewidth=4) draw3DRectangle(ax, xmin, ymin, zmin, xmax, ymax, zmax) . . Undo rotation and translatation to the data and bounding box coordinates . rectCoords = lambda x1, y1, z1, x2, y2, z2: np.array([[x1, x1, x2, x2, x1, x1, x2, x2], [y1, y2, y2, y1, y1, y2, y2, y1], [z1, z1, z1, z1, z2, z2, z2, z2]]) realigned_coords = np.matmul(evec, aligned_coords) realigned_coords += means[:, np.newaxis] rrc = np.matmul(evec, rectCoords(xmin, ymin, zmin, xmax, ymax, zmax)) # rrc = rotated rectangle coordinates . Translate the coordinates of the bounding box . rrc += means[:, np.newaxis] . Plot the data and the bounding box . fig = plt.figure() ax = fig.add_subplot(111, projection=&#39;3d&#39;) ax.scatter(realigned_coords[0,:], realigned_coords[1,:], realigned_coords[2,:], label=&quot;rotation and translation undone&quot;) ax.legend() # z1 plane boundary ax.plot(rrc[0, 0:2], rrc[1, 0:2], rrc[2, 0:2], color=&#39;b&#39;) ax.plot(rrc[0, 1:3], rrc[1, 1:3], rrc[2, 1:3], color=&#39;b&#39;) ax.plot(rrc[0, 2:4], rrc[1, 2:4], rrc[2, 2:4], color=&#39;b&#39;) ax.plot(rrc[0, [3,0]], rrc[1, [3,0]], rrc[2, [3,0]], color=&#39;b&#39;) # z2 plane boundary ax.plot(rrc[0, 4:6], rrc[1, 4:6], rrc[2, 4:6], color=&#39;b&#39;) ax.plot(rrc[0, 5:7], rrc[1, 5:7], rrc[2, 5:7], color=&#39;b&#39;) ax.plot(rrc[0, 6:], rrc[1, 6:], rrc[2, 6:], color=&#39;b&#39;) ax.plot(rrc[0, [7, 4]], rrc[1, [7, 4]], rrc[2, [7, 4]], color=&#39;b&#39;) # z1 and z2 connecting boundaries ax.plot(rrc[0, [0, 4]], rrc[1, [0, 4]], rrc[2, [0, 4]], color=&#39;b&#39;) ax.plot(rrc[0, [1, 5]], rrc[1, [1, 5]], rrc[2, [1, 5]], color=&#39;b&#39;) ax.plot(rrc[0, [2, 6]], rrc[1, [2, 6]], rrc[2, [2, 6]], color=&#39;b&#39;) ax.plot(rrc[0, [3, 7]], rrc[1, [3, 7]], rrc[2, [3, 7]], color=&#39;b&#39;) . . Conclusion . Using the Eigen-vectors we were able to generate a bounding box for the data we have at hand while carrying out translation, rotatation, and the conjugate operations. .",
            "url": "https://logicatcore.github.io/scratchpad/lidar/sensor-fusion/jupyter/2021/04/20/3D-Oriented-Bounding-Box.html",
            "relUrl": "/lidar/sensor-fusion/jupyter/2021/04/20/3D-Oriented-Bounding-Box.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "2D Oriented bounding boxes made simple",
            "content": "Overview . 2D oriented bounding box . Generating a bounding box around an object at first might sound trivial and fairly easy task to accomplish. But it is hardly the case when one starts to study the subject in detail, which is the case here. . What is a bounding box? . The answer to this question lies within the name but a bit of context is needed to make complete sense of it. &quot;Bounding box&quot; i.e. a box that bounds something, some object, or some living thing. We, as humans have a sense of this bounding box by which we imagine a bubble/sphere around an obstacle while driving, like the cat which always troubles me while crossing the road on my bicycle, I am thinking of naming that cat &quot;The Interruptor!&quot;, cause you know why. Anyway, so humans, imagine, sphere, avoid, obstacles! That is it, that is the motive behind why we are interested in such a box that bounds. Wait, you ask why did we shift from sphere to box? I think one possible reason is computers/autonoumous systems are capable of reacting much faster than us and the second and probably most important reason is to establish a definite NO-GO area which can later be enlarged based on a factor of safety. . Where do we use them? . That is a good question, isn&#39;t it? We use bounding boxes in autonoumous systems irrespective of the travel medium i.e. bounding boxes are used in self-driving cars, self-flying cars or copters etc. . What data are we working with? . In this post we work with some random data that emulates LIDAR data. But bounding boxes are used with both LIDAR pointclouds and digital images from a camera. . Read enough and want to see what is the fuss about? . Do not worry, I have got it covered for the skimmers (cause am also one of you (keep it a secret though 🤫)). In the following picture on the left we can see that though the box bounds the data but does so poorly by marking lot of empty space also as belonging to the data (imagine how bad one would feel if fatness was exaggerated, not good right!) and on the right we can see that the new oriented box bounds the data perfectly and only to the extent necessary hence proving the autonomous vehicle/entity enough space to steer through. . . . In this post the simple and yet informative 2D case is discussed as we move on to a 3D case in the next post. . . Let us get started with the code and the math to generate a bounding box . Handle some imports and set seed for the random generator . import matplotlib.pyplot as plt import numpy as np import numpy.linalg as LA # %matplotlib widget # uncomment this if you want to work with this notebook np.random.seed(22) . Generate 2D sample data and visualise it . x = np.random.normal(2, 2, (1, 100)) y = np.random.normal(1, 0.6, (1, 100)) plt.title(&quot;Raw data&quot;) plt.scatter(x, y) plt.ylim(-6, 8) plt.xlim(-6, 8) . (-6.0, 8.0) . Rotate the data . Note: The rotated data whill be principal data that we will be working with. We rotate the data to avoid the trivial case where an oriented bounding box result will be same as a max-min based bounding box . theta = 30 # rotation angle # rotation matrix rot = lambda theta: np.array([[np.cos(np.deg2rad(theta)), -np.sin(np.deg2rad(theta))], [np.sin(np.deg2rad(theta)), np.cos(np.deg2rad(theta))]]) # rotate the data using the rotation matrix data = np.matmul(rot(theta), np.vstack([x, y])) . plt.title(&quot;Rotated data&quot;) plt.scatter(data[0,:], data[1,:]) plt.ylim(-6, 8) plt.xlim(-6, 8) . (-6.0, 8.0) . Calculate means, covariance matrix, eigen values, and eigen vectors for the rotated data . means = np.mean(data, axis=1) # calculate the means # calculate the covariance matrix cov = np.cov(data) # Calculate the eigen values and eigen vectors of the covariance matrix eval, evec = LA.eig(cov) eval, evec . (array([3.92880689, 0.37119218]), array([[ 0.83553491, -0.54943736], [ 0.54943736, 0.83553491]])) . Now, so far we haven&#39;t given a name to the method that we will be using to achieve our goal and this seems to be the right time. The method that we will be using is called PCA(Prinicipal Component Analysis), now the machine learning enthusiasts out there would be having a question, isn&#39;t PCA a dimension reductionality algorithm used to reduce dimensions in the data? Yes and yes, you are correct but it also gives us insight that the eigen-vectors i.e. the vectors which do not changes direction upon transformation gives us the information about the directions in which the data is oriented in. . Hence, we will be making use of these eigen-vectors to align the data to our original cartesian basis vectors and use then use the max-min method to find oriented bounding boxes. . Simple max and min based bounding box . Let us have a look at the drawback so that we are in a position to appreciate our end result . def draw2DRectangle(x1, y1, x2, y2): # diagonal line # plt.plot([x1, x2], [y1, y2], linestyle=&#39;dashed&#39;) # four sides of the rectangle plt.plot([x1, x2], [y1, y1], color=&#39;r&#39;) # --&gt; plt.plot([x2, x2], [y1, y2], color=&#39;g&#39;) # | (up) plt.plot([x2, x1], [y2, y2], color=&#39;b&#39;) # &lt;-- plt.plot([x1, x1], [y2, y1], color=&#39;k&#39;) # | (down) . Translate the data to origin and compute the minimums and maximums of each dimension . centerd_data = data - means[:, np.newaxis] xmin, xmax, ymin, ymax = np.min(centerd_data[0,:]), np.max(centerd_data[0,:]), np.min(centerd_data[1,:]), np.max(centerd_data[1,:]) . Plot the translated data along with the principal components i.e. the two orthogonal eigen vectors . plt.title(&quot;Simple max-min based bounding box&quot;) plt.ylim(-6, 8) plt.xlim(-6, 8) plt.scatter(centerd_data[0,:], centerd_data[1,:]) draw2DRectangle(xmin, ymin, xmax, ymax) # plot the eigen vactors scaled by their eigen values plt.plot([0, eval[0] * evec[0, 0]], [0, eval[0] * evec[1, 0]], label=&quot;pc1&quot;, color=&#39;k&#39;) plt.plot([0, eval[1] * evec[0, 1]], [0, eval[1] * evec[1, 1]], label=&quot;pc2&quot;, color=&#39;k&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f14e92a9fa0&gt; . Calculate angle of the principal eigen vector . def getEigenAngle(v): return np.rad2deg(np.arctan(v[1]/v[0])) . theta_pc1 = getEigenAngle(evec[:, 0]) # the eigen vectors are usually returned sorted based on their eigenvalues, # so we use the eigen vector in first column theta_pc1 . 33.32842173633697 . Rotate the data to align to cartesian basis vectors . aligned_coords = np.matmul(rot(-theta_pc1), centerd_data) # notice the minus theta_pc1 angle . xmin, xmax, ymin, ymax = np.min(aligned_coords[0, :]), np.max(aligned_coords[0, :]), np.min(aligned_coords[1, :]), np.max(aligned_coords[1, :]) # compute the minimums and maximums of each dimension again . rectCoords = lambda x1, y1, x2, y2: np.array([[x1, x2, x2, x1], [y1, y1, y2, y2]]) . plt.title(&quot;Aligned data&quot;) # plot the rotated daa and its bounding box plt.ylim(-6, 8) plt.xlim(-6, 8) plt.scatter(aligned_coords[0,:], aligned_coords[1,:]) draw2DRectangle(xmin, ymin, xmax, ymax) . (-6.0, 8.0) . Rotate and translate the data back along with the oriented bounding box . rectangleCoordinates = rectCoords(xmin, ymin, xmax, ymax) . rotateBack = np.matmul(rot(theta_pc1), aligned_coords) # notice the plus theta_pc1 angle rectangleCoordinates = np.matmul(rot(theta_pc1), rectangleCoordinates) # translate back rotateBack += means[:, np.newaxis] rectangleCoordinates += means[:, np.newaxis] . plt.title(&quot;Re rotated and translated data&quot;) plt.ylim(-6, 8) plt.xlim(-6, 8) plt.scatter(rotateBack[0, :], rotateBack[1, :]) # four sides of the rectangle plt.plot(rectangleCoordinates[0, 0:2], rectangleCoordinates[1, 0:2], color=&#39;r&#39;) # | (up) plt.plot(rectangleCoordinates[0, 1:3], rectangleCoordinates[1, 1:3], color=&#39;g&#39;) # --&gt; plt.plot(rectangleCoordinates[0, 2:], rectangleCoordinates[1, 2:], color=&#39;b&#39;) # | (down) plt.plot([rectangleCoordinates[0, 3], rectangleCoordinates[0, 0]], [rectangleCoordinates[1, 3], rectangleCoordinates[1, 0]], color=&#39;k&#39;) # &lt;-- . (-6.0, 8.0) . And so, there we have it! We made use of eigen vectors to rotate and align the data and then use the max-min method to determine a bounding box and finally undone the rotation and translation to get our oriennted bounding box. . 2D Rotation example . This is just an additional illustration to show the rotation in action using the rotation matrix . x = np.matmul(rot(90), np.array([[2], [0]])) # rotate the vecctor (2, 0) by 90 degrees anti-clockwise . plt.plot([0, 2], [0, 0], label=&quot;Before rotation&quot;) plt.plot([0, x[0,0]], [0, x[1,0]], label=&quot;After rotation&quot;) plt.plot(2 * np.cos(np.linspace(0, np.pi/2, 50)), 2 * np.sin(np.linspace(0, np.pi/2, 50)), linestyle=&quot;dashed&quot;) plt.axis(&quot;equal&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f14e9384c40&gt; .",
            "url": "https://logicatcore.github.io/scratchpad/lidar/sensor-fusion/jupyter/2021/04/20/2D-Oriented-Bounding-Box.html",
            "relUrl": "/lidar/sensor-fusion/jupyter/2021/04/20/2D-Oriented-Bounding-Box.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "git, a learn by doing attempt",
            "content": "What is this article about? . This article is my attempt at solving the 23 exercises from https://gitexercises.fracz.com/. While some of the solutions do match exactly with the solutions shown after one successfully solves the exercises, the following collection of solutions are bit detailed in their descriptions along with some links pointing to resources which I found to be helpful in learning and solving the exercises. . Exercise 23 is the most interesting one and is also one of the solution I have spent some time working with gitpython module in developing an alternate method to find bug, in contrast to the git bisect solution presented on the main website. . Solutions . Exercise 1: master . $&gt; git start $&gt; git verify . Exercise 2: commit-one-file . $&gt; git add A.txt # or $&gt; git add B.txt $&gt; git commit -m &quot;add one file&quot; $&gt; git verify . Exercise 3: commit-one-file-staged . $&gt; git reset HEAD A.txt # or $&gt; git reset HEAD B.txt $&gt; git commit -m &quot;destage one file&quot; $&gt; git verify . Exercise 4: ignore-them . $&gt; nano .gitignore . *.exe *.o *.jar libraries/ . $&gt; git add . $&gt; git commit -m &quot;commit useful files&quot; $&gt; git verify . Exercise 5: chase-branch . $&gt; git checkout chase-branch $&gt; git merge escaped $&gt; git verify . Exercise 6: merge-conflict . $&gt; git checkout merge-conflict $&gt; git merge another-piece-of-work $&gt; nano equation.txt . 2 + 3 = 5 . $&gt; git add equation.txt $&gt; git commit -m &quot;merge and resolve&quot; $&gt; git verify . Exercise 7: save-your-work . To learn about stashing and cleaning https://git-scm.com/book/en/v2/Git-Tools-Stashing-and-Cleaning . $&gt; git stash # or $&gt; git stash push $&gt; nano bug.txt # in the text editor delete the bud line $&gt; git commit -am &quot;remove bug&quot; $&gt; git stash apply # or $&gt; git stash apply stash@{0} $&gt; nano bug.txt # in the text editor add the line &quot;Finally, finished it!&quot; to the end $&gt; git commit -am &quot;finish&quot; $&gt; git verify . Exercise 8: change-branch-history . To learn about git rebase https://git-scm.com/docs/git-rebase . $&gt; git checkout change-branch-history $&gt; git rebase hot-bugfix $&gt; git verify . Exercise 9: remove-ignored . Solution and explanation https://stackoverflow.com/questions/1274057/how-to-make-git-forget-about-a-file-that-was-tracked-but-is-now-in-gitignore . $&gt; git rm --cached ignored.txt $&gt; git commit -am &quot;untrack ignored.txt&quot; $&gt; git verify . Exercise 10: case-sensitive-filename . $&gt; git reset HEAD^ $&gt; mv File.txt file.txt $&gt; git add file.txt $&gt; git commit -m &quot;lowercase filename&quot; $&gt; git verify . Exercise 11: fix-typo . Note: --amend replaces the tip of the current branch by creating a new commit. . # fix typo in the file $&gt; git commit -a --amend # fix the typo in commit message $&gt; git verify . Exercise 12: forge-date (most useless exercise, but shows that git is not a monolith) . $&gt; git commit --amend --no-edit --date=&quot;1987-08-03&quot; . Exercise 13: fix-old-typo . $&gt; git rebase -i HEAD^^ # change &quot;pick&quot; to &quot;edit&quot; where the typo is in the commit message # fix the typo in the file $&gt; git add file.txt $&gt; git rebase --continue # fix the rebase conflict $&gt; git add file.txt $&gt; git reabse --continue $&gt; git verify . Exercise 14: commit-lost . $&gt; git reflog $&gt; git reset --hard HEAD@{1} $&gt; git verify . Exercise 15: split-commit . $&gt; git reset HEAD^ $&gt; git add first.txt $&gt; git commit -m &quot;First.txt&quot; $&gt; git add second.txt $&gt; git commit -m &quot;Second.txt&quot; $&gt; git verify . Exercise 16: too-many-commits . $&gt; git rebase -i HEAD~4 # replace &quot;pick&quot; with &quot;squash&quot; for the commit with the message &quot;Crap, I have forgotten to add this line.&quot; # leave a commit message same as the one with which the marked commit is getting squashed with i.e., # &quot;Add file.txt&quot; $&gt; git verify . Exercise 17: executable . Under the hood details https://stackoverflow.com/questions/40978921/how-to-add-chmod-permissions-to-file-in-git . $&gt; git update-index --chmod=+x script.sh $&gt; git commit -m &quot;make executable&quot; $&gt; git verify . Exercise 18: commit-parts . $&gt; git add --patch file.txt # split the hunks with &#39;s&#39; # Stage this hunk [y,n,q,a,d,/,j,J,g,s,e,?]? # # Here is a description of each option: # # y stage this hunk for the next commit # n do not stage this hunk for the next commit # q quit; do not stage this hunk or any of the remaining hunks # a stage this hunk and all later hunks in the file # d do not stage this hunk or any of the later hunks in the file # g select a hunk to go to # / search for a hunk matching the given regex # j leave this hunk undecided, see next undecided hunk # J leave this hunk undecided, see next hunk # k leave this hunk undecided, see previous undecided hunk # K leave this hunk undecided, see previous hunk # s split the current hunk into smaller hunks # e manually edit the current hunk # ? print hunk help # select each hunk with &#39;y&#39; or &#39;n&#39; $&gt; git commit -m &quot;task 1 related&quot; $&gt; git commit -am &quot;rest of the content&quot; $&gt; git verify . Exercise 19: pick-your-features . # get an idea of the logs currently and know the SHA-1&#39;s needed $&gt; git log --oneline --decorate --graph --all -8 $&gt; git checkout pick-your-features $&gt; git cherry-pick feature-a # or $&gt; git cherry pick SHA-1 of feature-a commit $&gt; git cherry-pick feature-b # or $&gt; git cherry pick SHA-1 of feature-b commit $&gt; git merge --squash feature-c # resolve conflict $&gt; git commit -am &quot;Complete Feature C&quot; $&gt; git verify . Exercise 20: reabse-complex . Explanation from git-book https://git-scm.com/book/en/v2/Git-Branching-Rebasing . $&gt; git rebase --onto your-master issue-555 rebase-complex # This basically says, “Take the rebase-complex branch, figure out the patches since it diverged from the issue-555 branch, # and replay these patches in the rebase-complex branch as if it was based directly off the your-master branch instead.” $&gt; git verify . Exercise 21: invalid-order . $&gt; git rebase -i HEAD~4 # reorder the commit messages as needed $&gt; git verify . Exercise 22: find-swearwords . $&gt; git log -S shit # make a note of the commits where a word &quot;shit&quot; was introduced $&gt; git rebase -i HEAD~105 # replace &#39;pick&#39; with &#39;edit&#39; for those commits # check which files were modified $&gt; git log -p -1 # replace &#39;shit&#39; with &#39;flower&#39; in list.txt $&gt; git add list.txt $&gt; git commit --amend $&gt; git rebase --continue # check which files were modified $&gt; git log -p -1 # replace &#39;shit&#39; with &#39;flower&#39; in words.txt $&gt; git add words.txt $&gt; git commit --amend $&gt; git rebase --continue # check which files were modified $&gt; git log -p -1 # replace &#39;shit&#39; with &#39;flower&#39; in words.txt $&gt; git add words.txt $&gt; git commit --amend $&gt; git rebase --continue $&gt; git verify . Exercise 23: find-bug . First method using git bisect$&gt; git checkout find-bug $&gt; git bisect start $&gt; git bisect bad $&gt; git bisect good 1.0 # the grep documentation for -v flag doesn&#39;t make sense with what the author fracz mentioned and also # I couldn&#39;t see the binary output of &#39;1&#39; or &#39;0&#39; as given in the hints $&gt; git bisect run sh -c &quot;openssl enc -base64 -A -d &lt; home-screen-text.txt | grep -v jackass&quot; $&gt; git push origin 4d2725ac4c874dbb207770001def27aed48e9ddb:find-bug . | Second method using gitpython . a. Brute-force method iterate through the commits one-by-one from oldest to the newest and break when the word &#39;jackass&#39; got introduced . | #!/usr/bin/env python # -*- coding:utf-8 -*- from git import Repo import base64 # create a repo object to query repo = Repo(&quot;./exercises/&quot;) # switch to the required branch repo.git.checkout(&#39;find-bug&#39;) # get all commits between HEAD and tag 1.0 commits = repo.iter_commits(&#39;HEAD...1.0&#39;) for x in reversed(list(commits)): # move the head to the commit &#39;x&#39; repo.head.set_reference(x) # get a tree object and query the blog based on the file name and read the content from it&#39;s data stream read_this = repo.tree(x)[&#39;home-screen-text.txt&#39;].data_stream.read() # reader = repo.config_reader() # read_this = open(&#39;./exercises/home-screen-text.txt&#39;) # decode the base64 bytes content = base64.b64decode(read_this).decode(&#39;ascii&#39;) # check if &#39;jackass&#39; is present in the file, if yes, print the SHA-1 and exit if &#39;jackass&#39; in content: print(&quot;The commit where the bug &#39;jackass&#39; was introduced is:&quot;, x.hexsha) break . b. Binary search method (newest first), very similar to what the *git bisect* command does . #!/usr/bin/env python # -*- coding:utf-8 -*- from git import Repo import base64 # create a repo object to query repo = Repo(&quot;./exercises/&quot;) # switch to the required branch repo.git.checkout(&#39;find-bug&#39;) # get all commits between HEAD and tag 1.0 commits = repo.iter_commits(&#39;HEAD...1.0&#39;) commits = list(commits) search_length = len(commits) idx = search_length//2 last_idx = 0 found_at = None for i in range(0, round(math.log2(search_length))): repo.head.set_reference(commits[idx]) read_this = repo.tree(commits[idx])[&#39;home-screen-text.txt&#39;].data_stream.read() content = base64.b64decode(read_this).decode(&#39;ascii&#39;) if &#39;jackass&#39; in content: found_at = idx print(commits[idx].hexsha) if i == 0: update = (search_length - idx)//2 else: update = (last_idx - idx)//2 last_idx = idx idx += abs(update) else: update = (idx - last_idx)//2 last_idx = idx idx -= abs(update) print(&quot;The commit where the bug &#39;jackass&#39; was introduced is:&quot;, commits[found_at].hexsha) .",
            "url": "https://logicatcore.github.io/scratchpad/git/2021/03/04/git-exercises.html",
            "relUrl": "/git/2021/03/04/git-exercises.html",
            "date": " • Mar 4, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Binary-Tree data structure and algorithms implementation",
            "content": "Recently I started learning standard algorithms from a theoretical standpoint i.e. their design, their complexities, and analysis of their complexities from the Introduction to Algorithms book by Thomas H.Cormen et.al. While I am learning I thought of also making it practical and implement all the details around the topic that I am learning. This post and the last one too are the result of this motivation. While the previous post details the automated testing that I had setup as a Github action to perform continuous integration, this post details the library itself with detailed examples. Each example is followed by an explanation of the and tries to details all the features of the library. . To follow along with the rest of the code, the libary can be easily installed using pip as follows- . pip install binary-tree-logicatcore . . To Begin with, we need to import BT (Binary-Tree) and Node classes to work with. . from binary_tree.binary_tree import BT, Node . A tree is composed of nested nodes with each node having two childrens, namely &#39;left&#39; and &#39;right&#39; which are also nodes. Hence the nesting continues. A node accepts a value to store and another two optional nodes to act as its left and right children. Below is an example of a node with &#39;1&#39; as the value and with two childrens left and right each with a value of &#39;2&#39; and &#39;3&#39;, which are also nodes. . Node(1, Node(2), Node(3)) . 1 / 2 3 . A binary tree consists of such nodes nested allowing the tree to grow in height/depth with the addition of nodes. Below an example showing one way of defining a binary tree very similar to the previous example. A binary tree class accepts a single root node which may or may not have left and right childrens. In the following example, the root node has two childrens and the two childrens have 4 childrens, two respectively. The last 4 childrens do not have any childrens and hence are called leafs generally (end points of the tree) . tree = BT(Node(1, Node(2, Node(4), Node(5)), Node(3, Node(6), Node(7)))) . The created tree can be visualised in two ways- . Using graphviz | In ASCII style | tree.graphviz() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_2 cluster_1 cluster_0 20 1 10 3 20&#45;&gt;10 11 2 20&#45;&gt;11 00 7 10&#45;&gt;00 01 6 10&#45;&gt;01 02 5 11&#45;&gt;02 03 4 11&#45;&gt;03 tree.ASCII() . 1 _______|______ | | 2 3 ___|___ ___|___ | | | | 4 5 6 7 . The main properties of the binary tree can be quickly and easily summarised by calling the properties method as follows. . tree.properties() . Total number of elements in the tree are: 7 Total number of nodes are: 3 Total number of leafs are: 4 The depth of the tree is: 2 The maximum value in the tree is: 7 The minimum value in the tree is: 1 1 _______|______ | | 2 3 ___|___ ___|___ | | | | 4 5 6 7 . The second way of creating a similar tree is through using python lists, which is quick and enables building much deeper trees. But, certain level of control over deciding which nodes must have left children or right children or both or none is lost in doing so. . list_tree = BT([1,2,3,4,5,6,7]) . list_tree.graphviz() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_2 cluster_1 cluster_0 20 1 10 3 20&#45;&gt;10 11 2 20&#45;&gt;11 00 7 10&#45;&gt;00 01 6 10&#45;&gt;01 02 5 11&#45;&gt;02 03 4 11&#45;&gt;03 list_tree.ASCII() . 1 _______|______ | | 2 3 ___|___ ___|___ | | | | 4 5 6 7 . list_tree.properties() . Total number of elements in the tree are: 7 Total number of nodes are: 3 Total number of leafs are: 4 The depth of the tree is: 2 The maximum value in the tree is: 7 The minimum value in the tree is: 1 1 _______|______ | | 2 3 ___|___ ___|___ | | | | 4 5 6 7 . As it can be seen that the result is same in this case i.e. the resulting tree created by manually nesting the nodes and the resulting tree created using lists both are same. . Tree related algorithms . Since a binary tree is not meant to be simple data structure, there are some algorithms that have evloved around it which reduce the number of comuptations required, such as heapsort which takes $O(nlog(n))$ time. . Like the tree in real world, there are some binary trees which are unique because of it&#39;s characteristics. Two such properties are- . Max-Heap: The property that the parent node always has a larger value than its childrens through out the tree | Min-Heap: The property that the parent node always has a smaller value than its childrens through out the tree | The tree object comes with methods which when called automatically adjusts the positions of nodes in order to maintain these properties. Below we will look at an example on how to use these methods in order to alter the tree to maintain the properties desired. . Max-Heap and Min-Heap . unordered_tree = BT([1,10,2,9,3,8,4,7,5,6]) . unordered_tree.graphviz() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_3 cluster_2 cluster_1 cluster_0 30 1 20 2 30&#45;&gt;20 21 10 30&#45;&gt;21 10 4 20&#45;&gt;10 11 8 20&#45;&gt;11 12 3 21&#45;&gt;12 13 9 21&#45;&gt;13 00 6 12&#45;&gt;00 01 5 13&#45;&gt;01 02 7 13&#45;&gt;02 As it is evident that the tree doesn&#39;t satisfy the property, now we will use the max_heapify() method and min_heapify() method to change the tree and check again . unordered_tree.max_heapify() # inplace change . unordered_tree.graphviz() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_3 cluster_2 cluster_1 cluster_0 30 10 20 8 30&#45;&gt;20 21 9 30&#45;&gt;21 10 4 20&#45;&gt;10 11 2 20&#45;&gt;11 12 6 21&#45;&gt;12 13 7 21&#45;&gt;13 00 3 12&#45;&gt;00 01 5 13&#45;&gt;01 02 1 13&#45;&gt;02 In this new tree graph we can see that the parent node value is always larger than the value of it&#39;s childrens, grand-childrens, great-grand-childrens and so on.... . unordered_tree.min_heapify() # inplace change . unordered_tree.graphviz() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_3 cluster_2 cluster_1 cluster_0 30 1 20 2 30&#45;&gt;20 21 3 30&#45;&gt;21 10 4 20&#45;&gt;10 11 8 20&#45;&gt;11 12 6 21&#45;&gt;12 13 5 21&#45;&gt;13 00 10 12&#45;&gt;00 01 9 13&#45;&gt;01 02 7 13&#45;&gt;02 In this tree graph we can now see that the parent node value is always smaller than the value of it&#39;s childrens, grand-childrens, great-grand-childrens and so on.... . Heap Sort . On the look of it, heap sort results look and feel to the user as the results of any other type of sorting method. The main difference however comes in the implementation and the time complexity. . from binary_tree.heap_sort import heap_sort_asc, heap_sort_desc import numpy as np . test_list = np.random.randint(0, 100, size=(1, 20)).tolist()[0] print(&quot;Random list of 20 numbers:&quot;, test_list) print(&quot;Heap sort in ascending order:&quot;, heap_sort_asc(test_list)) print(&quot;Heap sort in descending order:&quot;, heap_sort_desc(test_list)) . Random list of 20 numbers: [95, 53, 52, 59, 86, 32, 26, 27, 64, 64, 76, 41, 27, 83, 57, 0, 73, 35, 19, 76] Heap sort in ascending order: [0, 19, 26, 27, 27, 32, 35, 41, 52, 53, 57, 59, 64, 64, 73, 76, 76, 83, 86, 95] Heap sort in descending order: [95, 86, 83, 76, 76, 73, 64, 64, 59, 57, 53, 52, 41, 35, 32, 27, 27, 26, 19, 0] . Priority queues . A priority queue is a data structure for maintaining a set S of elements, each with an associated value called a key. And as with heaps, priority queues come in two forms: max-priority queues and min-priority queues. . A max-priority queue supports the following operations: . INSERT(S, x) inserts the element x into the set S, which is equivalent to the operation $S = S cup {x}$ | MAXIMUM(S) returns the element of S with the largest key. | EXTRACT-MAX(S) removes and returns the element of S with the largest key. | INCREASE-KEY(S, x, k) increases the value of element x’s key to the new value k, which is assumed to be at least as large as x’s current key value. | . And a min-priority queue supports the following operations: . INSERT(S, x) inserts the element x into the set S, which is equivalent to the operation $S = S cup {x}$ | MINIMUM(S) returns the element of S with the smallest key. | EXTRACT-MIN(S) removes and returns the element of S with the smallest key. | DECREASE-KEY(S, x, k) decreases the value of element x’s key to the new value k, which is assumed to be at least as small as x’s current key value. | . from binary_tree.priority_queue import MaxPQueue, MinPQueue . Max-Priority Queue . To explain a max-priority queue let us consider a simple sentence and since we know that the word order in English language is important, this means that each word has certain priority. We will try to use the max-priority queue to correctly order a set of words and punctuations based on their priorities. . Maximum and Extract-Max functionality . Initially here we want to correctly order &#39;Hello&#39;, &#39;!&#39; and &#39;World&#39; words and a punctuation in the correct order for which we assign corresponding priority values as a 1-to-1 mapping to the &#39;MaxPQueue&#39; class. Then we check which word has the highest priority and then the order of all the objects(words, punctuations) in the queue. . max_queue = MaxPQueue([3,1,2],[&#39;Hello&#39;, &#39;!&#39;, &#39;World&#39;]) . max_queue.max() . &#39;Hello&#39; . while len(max_queue.objects) &gt; 0: print(max_queue.get_max(), end=&#39; &#39;) . Hello World ! . Insert functionality . Mid way we realise that we forgot to add some details and would like add them, for this purpose we use the insert functionality to add an adjective that qualifies the noun in sentence i.e. &#39;World&#39; with a priority that if less than that of &#39;Hello&#39; but more than that of &#39;World&#39; . max_queue = MaxPQueue([3,1,2],[&#39;Hello&#39;, &#39;!&#39;, &#39;World&#39;]) max_queue.heap_insert(&#39;beautiful&#39;, 2.5) while len(max_queue.objects) &gt; 0: print(max_queue.get_max(), end=&#39; &#39;) . Hello beautiful World ! . Increase-Key functionality . While adding certain details (events/tasks/objects) to the queue, if we happen to assign an incorrect key or if the priorities have changed (for example in a real world production factory where the product being produced needs to adapt to the market), we can use the increase_key functionality as follows. Here we try to add the words &#39;Max&#39; and &#39;says&#39; but do it incorrectly thus we decide to correct it using the increase_key method . max_queue = MaxPQueue([3,1,2],[&#39;Hello&#39;, &#39;!&#39;, &#39;World&#39;]) max_queue.heap_insert(&#39;Max&#39;, 2.5) max_queue.heap_insert(&#39;says&#39;, 2.8) max_queue.increase_key(&#39;Max&#39;, 5) max_queue.increase_key(&#39;says&#39;, 4) while len(max_queue.objects) &gt; 0: print(max_queue.get_max(), end=&#39; &#39;) . Max says Hello World ! . Min-Priority Queue . A min-priority queue can also be logically understood using a simple example where the day activities are ordered based on time and since time is linear in nature the smallest must come first and the largest later. . Minimum and Extract-Min functionality . In the following example certain day activities are listed along with the ideal time for them to take place in a 24 hr format. . min_queue = MinPQueue([9,19,13,22,6],[&#39;Breakfast&#39;, &#39;Dinner&#39;, &#39;lunch&#39;, &#39;sleep&#39;, &#39;wakeup&#39;]) . min_queue.min() . &#39;wakeup&#39; . while len(min_queue.objects) &gt; 0: print(min_queue.get_min(), end=&#39; -&gt; &#39;) . wakeup -&gt; Breakfast -&gt; lunch -&gt; Dinner -&gt; sleep -&gt; . Insert functionality . While planning we forget to include studies so like in the previous case where we added an adjective, here to we can insert a &#39;study&#39; task into the queue . min_queue = MinPQueue([9,19,13,22,6],[&#39;Breakfast&#39;, &#39;Dinner&#39;, &#39;lunch&#39;, &#39;sleep&#39;, &#39;wakeup&#39;]) min_queue.heap_insert(&#39;study&#39;, 10) while len(min_queue.objects) &gt; 0: print(min_queue.get_min(), end=&#39; -&gt; &#39;) . wakeup -&gt; Breakfast -&gt; study -&gt; lunch -&gt; Dinner -&gt; sleep -&gt; . Decrease-Key functionality . Like in the previous case of max-priority queue while inserting certain tasks like to &#39;brush&#39; teeths and to &#39;play&#39; because in the former we made a mistake and in the later we didn&#39;t realise the day to be holiday. . min_queue = MinPQueue([9,19,13,22,6],[&#39;Breakfast&#39;, &#39;Dinner&#39;, &#39;lunch&#39;, &#39;sleep&#39;, &#39;wakeup&#39;]) min_queue.heap_insert(&#39;brush&#39;, 10) min_queue.heap_insert(&#39;play&#39;, 17) min_queue.decrease_key(&#39;brush&#39;, 7) min_queue.decrease_key(&#39;play&#39;, 10) while len(min_queue.objects) &gt; 0: print(min_queue.get_min(), end=&#39; -&gt; &#39;) . wakeup -&gt; brush -&gt; Breakfast -&gt; play -&gt; lunch -&gt; Dinner -&gt; sleep -&gt; .",
            "url": "https://logicatcore.github.io/scratchpad/python/testing/continuous-integration/2021/02/23/Binary-Tree.html",
            "relUrl": "/python/testing/continuous-integration/2021/02/23/Binary-Tree.html",
            "date": " • Feb 23, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Automated python testing on Github",
            "content": "To beging with, let us go through some basic definition of what Continuous Integration is and what we want to achieve with the tools that are available. . What is CI(continuous integration)? . While there are plenty of excellent resources online to read about whta CI is and what are its advantages. Continuous Integration (CI) in its simplest interpretation is a development practice where developers integrate their work (code) into a shared repository frequently, preferably several times a day. With each integration being verified by an automated build and tests. . One of the key benefits of integrating regularly is that errors can be easily detected and located. CI has become a best practice for software development and is guided by a set of key principles. Among them are revision control, build automation and automated testing. . “Continuous Integration doesn’t get rid of bugs, but it does make them dramatically easier to find and remove.” -Martin Fowler, Chief Scientist, ThoughtWorks . Sounds good, how to proceed next? . Well, their are multiple solutions/ways in which one can setup CI. Perhaps you have heard of jenkins, which &quot;is a free and open source automation server that helps automate the parts of software development related to building, testing, and deploying, facilitating continuous integration and continuous delivery&quot;. . But, Github also offers the necessary tools required to achieve what jenkins perhaps (not from experience) makes it easy since it has been specifically developed for automation. Github enables setting up workflows which can in turn be used create custom continuous integration (CI) and continuous deployment (CD) workflows directly in one&#39;s GitHub repository with GitHub Actions. . In this post we will be mainly looking at how to make use of Github actions to setup a Continuous integrations workflow where tests are performed upon each pull request and the test statistics are displayed right at the pull request which would help both the integrator and the code contributor to identify and rectify errors easily before the work can be merged into the main or development branch. . Python testing framework . Pytest is a python testing framework that we will be using. The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries. . An example of simple test: . def inc(x): return x + 1 def test_answer(): assert inc(3) == 5 . Pytest has neat feature using which all files of the form test_*.py or *_test.py in the current directory and its subdirectories can be run automatically. The results of the test can then be summarised into an xml file which can be read by an automated process to further generate easily interpretable graphs/graphics. . Generating graphs/graphics . In the previous section we got to know about the testing framework which can run the tests on demand and also summarises the results into an xml which can be used by automated processes to generate easily interpretable graphs/graphics. . For this purpose we will make use of an Github-action made by Enrico Minack which analyses Unit Test result files(xml) and publishes the results on GitHub. It supports the JUnit XML file format. Here is an example of a comment posted on the pull request of the commit that triggers the workflow, if one exists. In presence of failures or errors, the comment links to the respective check page with failure details: . . Setting up Github action for Python testing . If the reader is not familar with what Github actions are, I highly recommend spending some time to read through the following introduction website which explains introduces Github actions clearly and concisely. . By default the github actions are meant to be stored inside a .github/workflows folder as yml files. This is where we will be creating a file named python-testing.yml and define all the relevant details regarding the automated workflow that we want to set up. . yml # This is a basic workflow to help you get started with Actions name: Binary-Tree-Python-Testing # Controls when the action will run. on: # Triggers the workflow on pull request events but only for the devel branch pull_request: branches: [ devel ] # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # A workflow run is made up of one or more jobs that can run sequentially or in parallel jobs: # This workflow contains a single job called &quot;test&quot; test: # The type of runner that the job will run on runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 # Pick the python version with which you want the tests to be carried out. &#39;x&#39; allows github to pick the lastest stable version available - name: Set up Python uses: actions/setup-python@v2 with: python-version: &#39;3.8.x&#39; # Install pytest and pytest-cov (code coverage) in the virtual runner to run the tests. pytest also summarises the test results in an xml file which will be used by the action in the next step to generate some graphics and post as comment at the commit/pull request that triggers the automated tesing workflow - name: Test with pytest run: | pip install pytest pip install pytest-cov pytest --doctest-modules --junitxml=junit/test-results.xml --cov=com --cov-report=xml --cov-report=html # Publish the results of testing as a graphical summary in the conversation of the pull request that triggered the action (from the previous section) - name: Publish Unit Test Results uses: EnricoMi/publish-unit-test-result-action@v1 if: always() with: files: junit/test-results.xml GITHUB_TOKEN: $ . Automated testing in action!! . Now that we have everything set up, we can see the automated testing workflow in action. Since the workflow has been configured to run upon a pull request being made to the devel (development) branch, any pull request that is made to the devel branch triggers the workflow and the results of the testing will be posted. . Since I had started to work on creating a library of binary-tree data structure and the relevant algorithms, I have this workflow setup for my own repository which I have been using to integrate changes and updates to the library I am building. Here is the most recent pull request I myself made to the library that I am working on to emulate an actual development process/environment. In the pull request below, I have added priority queues functionatily along with relevant test cases which test the functionality. . . This form of testing enables a form of feeback loop to the developers who can be sure that the new changes do not break the old work and just build upon or expand the functionalities. . . If you have any questions or need any help do not hesitate to reach out to me via comments! .",
            "url": "https://logicatcore.github.io/scratchpad/python/testing/continuous-integration/2021/02/16/Automated-Python-Testing-On-Github.html",
            "relUrl": "/python/testing/continuous-integration/2021/02/16/Automated-Python-Testing-On-Github.html",
            "date": " • Feb 16, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "K-Means from scratch visualised with 1D, 2D and 3D data",
            "content": "Concept . K-Means is a unsupervised clustering algorithm which is analogous to supervised classification algorithms. Due to the name, K-Means algorithm is often confused with supervised KNN(K Nearest Neighbhours) algorithm which is used for both classification and regression problems. . As the name suggests, K-Means algorithm comprises of &quot;K&quot; &quot;Means&quot; which correspond to the number of clusters that the algorithm tries to find in the unlabeled data. The working of the algorithm though quite simple the challenge lies in scaling the algorithm for large datasets and picking an appropriate measure for distance. . Before we go into any more details, let us have a look at the steps that comprise the K-Means algorithm- . Inputs to the algorithm- Data to cluster | Number of clusters to identify | Convergence criteria i.e. when to stop Usually a tolerance value is given which is used to observe when the &quot;Mean&quot; position doesn&#39;t change any more | Other option is the maximum number of iterations to carry out | | Function to use as a Measure - usually cartesian distance is used but when data is text or any other abstract data, special measures have to be choosen | | Based on the data space i.e. the bounds (minimums and maximums) and the number of clusters to identify, that many random Mean points in the same space as the data are generated | Distance of all the data samples/points in the data space, say $ mathbb{R}^n$, with resepect to K number of Means are calculated (i.e. if there are 10 samples and 2 clusters to find, the number of distance measures calculated are 20(1x10 + 1x10)) | Based on the distances each data sample is associated to their closest Mean | Based on the associations made in step 4 the Mean values are updated by calculating the mean of all the values associated with one particular Mean. This is done for K number of Means | The steps 3 to 5 are then repeated either until the algorithm exceeds the maximum number of allowed iterations or until the values of K Means have settled down i.e. the change after update is less than the tolerance value specified in the input | Next, we turn to the implementation and coding part of the algorithm and discuss the results. . Code start . Handling the imports . %matplotlib widget import time import IPython import numpy as np import pandas as pd import numpy.linalg as LA import matplotlib.pyplot as plt from matplotlib import animation from mpl_toolkits.mplot3d import Axes3D from IPython.display import Video plt.rcParams[&#39;figure.figsize&#39;] = [8.0, 8.0] plt.rcParams[&#39;figure.dpi&#39;] = 100 . K-Means class to hold data, methods to compute the distances, update the means, and plot the progress and results . class kmeans: def __init__(self, dimensions, sample_size, clusters, tolerance, max_iters): &quot;&quot;&quot; Use the initialisation parameters as attributes of the object and create a matplotlib figure canvas on which each iteration progress can be drawn :param dimesnions: Dimension of data :param sample_size: Not necessary for real data, here used for generating sample data :param clusters: Number of clusters to identify in the data, control the number of Means :param tolerance: The tolearance value :param max_iters: Maximum iterations to execute &quot;&quot;&quot; self.dimensions = dimensions self.sample_size = sample_size self.clusters = clusters self.tolerance = tolerance self.max_iters = max_iters self.colors = [&#39;y&#39;, &#39;r&#39;, &#39;b&#39;, &#39;m&#39;, &#39;k&#39;, &#39;c&#39;, &#39;b&#39;, &#39;m&#39;, &#39;k&#39;, &#39;c&#39;] if self.dimensions == 1: self.fig, self.ax = plt.subplots(1,1) self.sample_pts = np.array([[]]) self.ax.grid(True) elif self.dimensions == 2: self.fig, self.ax = plt.subplots(1,1) self.sample_pts = np.array([[], []]) self.ax.grid(True) elif self.dimensions == 3: self.fig = plt.figure(1, figsize=(8, 6)) self.sample_pts = np.array([[], [], []]) self.ax = Axes3D(self.fig, rect=(0.0, 0.0, .95, 1.0), elev=48, azim=134) def kmeans_init(self): &quot;&quot;&quot; Generate sample data and draw the initial state of the data and display the initial position of the Means &quot;&quot;&quot; ################################################################################################################################## # Creating clusters using normal distribution and random variance and mean # every cluster will have equal number of points ################################################################################################################################## for i in range(0, self.clusters): np.random.seed(int((-i) ** 2)) tmp = np.random.randn(1, (self.sample_size // self.clusters) * self.dimensions) * np.random.randint(1, 10) + np.random.randint(-100, 100) self.sample_pts = np.hstack((self.sample_pts, tmp.reshape(self.dimensions, self.sample_size // self.clusters))) np.random.seed(22) self.previous_means = np.random.randn(self.clusters, self.dimensions) * np.random.randint(1, 12) # Randomly selected means i.e., cluster centers # print(f&#39;Starting means are: {self.previous_means}&#39;) self.new_means = np.zeros((self.clusters, self.dimensions)) # To store the new means after every iteration ################################################################################################################################## # plot initial means and all data samples to see the distribution ################################################################################################################################## if self.dimensions == 1: self.ax.scatter(self.previous_means[:, 0], np.zeros((self.clusters, 1)), marker=&#39;o&#39;, c=&#39;r&#39;, label=&#39;Initial Means&#39;) self.ax.scatter(self.sample_pts[0, :], np.zeros((1, self.sample_size)), marker=&#39;*&#39;) # Plotting all the points to see the clusters elif self.dimensions == 2: self.ax.scatter(self.previous_means[:, 0], self.previous_means[:, 1], marker=&#39;o&#39;, c=&#39;r&#39;, label=&#39;Initial Means&#39;) self.ax.scatter(self.sample_pts[0, :], self.sample_pts[1, :], marker=&#39;*&#39;) # Plotting all the points to see the clusters elif self.dimensions == 3: self.ax.scatter(self.previous_means[:, 0], self.previous_means[:, 1], self.previous_means[:, 2], marker=&#39;o&#39;, c=&#39;r&#39;, label=&#39;Initial Means&#39;, depthshade=False) self.ax.scatter(self.sample_pts[0, :], self.sample_pts[1, :], self.sample_pts[2, :], marker=&#39;*&#39;) # Plotting all the points to see the clusters self.ax.legend(loc=&#39;upper right&#39;) ################################################################################################################################## # Loop till convergence ################################################################################################################################## def kmeans_iter(self, iteration_count): &quot;&quot;&quot; Iteration part of the algorithm which iterates until the tolerance criteria is met while limiting the maximum number of iterations to preven infinite loops when the algorithm cannot associate a Mean value with a cluster &quot;&quot;&quot; if (abs(self.previous_means - self.new_means) &gt; self.tolerance).any() and (iteration_count &lt; self.max_iters) and (iteration_count != 0): print(f&#39;Iteration number {iteration_count}&#39;) if iteration_count != 1: self.previous_means = self.new_means.copy() dist = pd.DataFrame() ################################################################################################################################## # Compute distances of all points with respect to each mean ################################################################################################################################## for i in range(0, self.clusters): # distance_to_mean_1_iter_1 naming used dist[&#39;dtm_&#39; + str(i + 1) + f&#39;_iter_{iteration_count}&#39;] = LA.norm( self.sample_pts - self.previous_means[i, :].T.reshape(self.dimensions, 1), axis=0) # Assign a data sample to the mean it is nearest to by extracting the digit in the name of the index i.e., column # name where the minimum value is found # dtm_{1}_iter_1 dist[&#39;assign_to_mean&#39;] = dist.idxmin(axis=1).str[4] ################################################################################################################################## # compute the new means based on the classes assigned ################################################################################################################################## for i in range(0, self.clusters): indices = dist.assign_to_mean[dist.assign_to_mean == str(i + 1)] if self.dimensions &gt; 1: if len(indices.index) != 0: self.new_means[i, :] = np.mean(self.sample_pts[:, indices.index], axis=1) else: # Re-initialise a mean if it is not associated with any data sample self.new_means[i, :] = np.random.randn(1, self.dimensions) * 100 else: if len(indices.index) != 0: self.new_means[i, 0] = np.mean(self.sample_pts[0, indices.index]) else: # Re-initialise a mean if it is not associated with any data sample self.new_means[i, 0] = np.random.randn(1, self.dimensions) * 100 # print(f&#39;New means are:{self.new_means}&#39;) ################################################################################################################################## # Plot the movement of the means ################################################################################################################################## if self.dimensions == 1: for i in range(0, self.clusters): self.ax.plot([self.previous_means[i, 0], self.new_means[i, 0]], [0, 0], label=&#39;mean movement&#39; if iteration_count == 1 else &quot;&quot;, c=self.colors[i]) self.ax.scatter(self.new_means[i, 0], 0, marker=&#39;o&#39;, c=&#39;g&#39;, label=&#39;new Means&#39; if i == 0 and iteration_count == 1 else &quot;&quot;) elif self.dimensions == 2: for i in range(0, self.clusters): self.ax.plot([self.previous_means[i, 0], self.new_means[i, 0]], [self.previous_means[i, 1], self.new_means[i, 1]], label=&#39;mean movement&#39; if iteration_count == 1 else &quot;&quot;, c=self.colors[i]) self.ax.scatter(self.new_means[i, 0], self.new_means[i, 1], marker=&#39;o&#39;, c=&#39;g&#39;, label=&#39;new Means&#39; if i == 0 and iteration_count == 1 else &quot;&quot;) elif self.dimensions == 3: for i in range(0, self.clusters): self.ax.plot([self.previous_means[i, 0], self.new_means[i, 0]], [self.previous_means[i, 1], self.new_means[i, 1]], [self.previous_means[i, 2], self.new_means[i, 2]], label=&#39;mean movement&#39; if iteration_count == 1 else &quot;&quot;, c=self.colors[i]) self.ax.scatter(self.new_means[i, 0], self.new_means[i, 1], self.new_means[i, 2], marker=&#39;o&#39;, c=&#39;g&#39;, label=&#39;new Means&#39; if i == 0 and iteration_count == 1 else &quot;&quot;) self.ax.legend(loc=&#39;upper right&#39;) # iteration_count += 1 # self.fig.canvas.draw() ################################################################################################################################## # Plot the clustering results upon convergence ################################################################################################################################## if (abs(self.previous_means - self.new_means) &lt; self.tolerance).all(): cluster_pts = [] division = self.sample_size // self.clusters if self.dimensions == 1: for i in range(0, self.clusters): indices = dist.assign_to_mean[dist.assign_to_mean == str(i + 1)] cluster_pts.append(len(indices.index)) self.ax.scatter(self.sample_pts[0, indices.index], np.zeros((1, cluster_pts[i])), marker=&#39;*&#39;, label=f&#39;predicted cluster {i + 1}&#39;) self.ax.scatter(self.sample_pts[0, i * division:(i + 1) * division - 1], np.zeros((1, division - 1)), marker=&#39;o&#39;, facecolors=&#39;none&#39;, edgecolors=self.colors[i], s=200, linewidths=2, label=f&#39;real cluster {i + 1}&#39;) elif self.dimensions == 2: for i in range(0, self.clusters): indices = dist.assign_to_mean[dist.assign_to_mean == str(i + 1)] cluster_pts.append(len(indices.index)) self.ax.scatter(self.sample_pts[0, indices.index], self.sample_pts[1, indices.index], marker=&#39;*&#39;, label=f&#39;predicted cluster {i + 1}&#39;) self.ax.scatter(self.sample_pts[0, i * division:(i + 1) * division - 1], self.sample_pts[1, i * division:(i + 1) * division - 1], marker=&#39;o&#39;, facecolors=&#39;none&#39;, edgecolors=self.colors[i], s=200, linewidths=2, label=f&#39;real cluster {i + 1}&#39;) elif self.dimensions == 3: for i in range(0, self.clusters): indices = dist.assign_to_mean[dist.assign_to_mean == str(i + 1)] cluster_pts.append(len(indices.index)) self.ax.scatter(self.sample_pts[0, indices.index], self.sample_pts[1, indices.index], self.sample_pts[2, indices.index], marker=&#39;*&#39;, label=f&#39;predicted cluster {i + 1}&#39;) self.ax.scatter(self.sample_pts[0, i * division:(i + 1) * division - 1], self.sample_pts[1, i * division:(i + 1) * division - 1], self.sample_pts[2, i * division:(i + 1) * division - 1], marker=&#39;o&#39;, label=f&#39;real cluster {i + 1}&#39;, s=40) # facecolors=&#39;none&#39;, edgecolors=self.colors[i], s=200, linewidths=2) ################################################################################################################################## # set title with the clustering results and show legend ################################################################################################################################## if self.dimensions &lt; 3: self.ax.set_title(&#39;Number of points in each cluster are: &#39; + str(cluster_pts)) self.ax.legend(loc=&#39;upper right&#39;) else: self.ax.text2D(0.05, 0.95, &#39;Number of points in each cluster are: &#39; + str(cluster_pts), transform=self.ax.transAxes) self.ax.legend(loc=&#39;upper right&#39;) . Animation parameters . fps = 0.5 Writer = animation.writers[&#39;ffmpeg&#39;] writer = Writer(fps=fps, metadata=dict(artist=&#39;Sai&#39;), bitrate=1800) . 1D example of K-Means in action . max_iterations = 5 kmeans1d = kmeans(dimensions=1, sample_size=100, clusters=2, tolerance=1e-8, max_iters=max_iterations) animation.FuncAnimation(kmeans1d.fig, kmeans1d.kmeans_iter, init_func=kmeans1d.kmeans_init ,frames=max_iterations, interval=(1/fps)*1000, repeat=False).save(&#39;../images/kmeans/kmeans_1D.mp4&#39;, writer=writer); . In the video/animation below initially the data points in 1D space belonging to two clusters along with the initial random generated means are shown. After which the movement of means is shown and once the mean values are converged the results are shown. Since the data is being manually generated here, there is a possibility of verify how accurate the results are. As a last step for the verification, the predicted/identified clusters along with the supposed real clusters details are shown. . In this particular case the K-Means algorithm clusters accurately with 50 1D data samples of each of the two clusters. . Video(&quot;../images/kmeans/kmeans_1D.mp4&quot;, embed=True) . Your browser does not support the video tag. 2D example of K-Means in action . max_iterations = 15 kmeansnn2d = kmeans(dimensions=2, sample_size=600, clusters=4, tolerance=1e-8, max_iters=max_iterations) animation.FuncAnimation(kmeans2d.fig, kmeans2d.kmeans_iter, init_func=kmeans2d.kmeans_init ,frames=max_iterations, interval=(1/fps)*1000, repeat=False).save(&#39;../images/kmeans/kmeans_2D.mp4&#39;, writer=writer); . Like in previous case, here instead of 1D data samples 2D data samples are being used to cluster with the objective of identifying 4 clusters in the data. The movement of one of the Mean value if haphazard/chaotic because when a Mean cannot associate with any of the data sample, the position of the Mean is again randomly initialised, this randomness ensures that exactly 4 clusters will be found even if the starting position of the Mean values are not ideal. . In this case we also get to see that the clustering is not 100% accurate, as the final clustering results result in 150, 150, 152 and 148 data samples being associated to each cluster which ideally should have been a even 150 value for all the 4 clusters. . Video(&quot;../images/kmeans/kmeans_2D.mp4&quot;, embed=True) . Your browser does not support the video tag. 3D example of K-Means in action . max_iterations = 8 kmeans3d = kmeans(dimensions=3, sample_size=300, clusters=3, tolerance=1e-8, max_iters=max_iterations) animation.FuncAnimation(kmeans3d.fig, kmeans3d.kmeans_iter, init_func=kmeans3d.kmeans_init ,frames=max_iterations, interval=(1/fps)*1000, repeat=False).save(&#39;../images/kmeans/kmeans_3D.mp4&#39;, writer=writer); . Like in previous cases, here instead of 1D or 2D data samples 3D data samples are being used to cluster with the objective of identifying 3 clusters in the data. . Video(&quot;../images/kmeans/kmeans_3D.mp4&quot;, embed=True) . Your browser does not support the video tag. Remarks . In this post/jupyter notebook the distance measure used is the &quot;cartesian distance&quot;, but other distance measures like &quot;cosine&quot; distance can also be used. In this post/jupyter notebook the data used is also randomly generated numerical data, but when data is textual the implementation details vary. .",
            "url": "https://logicatcore.github.io/scratchpad/machine%20learning/jupyter/2021/01/15/K-Means.html",
            "relUrl": "/machine%20learning/jupyter/2021/01/15/K-Means.html",
            "date": " • Jan 15, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Vanilla Regression Decision Tree example",
            "content": "Decision Tree . What is a decision tree? . Well, a decision tree is the most simplistic way of reasoning to find order in chaos or a system. Although very rudimentry in nature, decision trees and its varients(bagging methods and boosting methods) are capable of mapping i.e. finding the order in data to a very high degree of accuracy. Decision trees are mainly binary tress comprising of if-else statements that determine the split lines, planes or hyperplanes which breaks down the data space in $ mathbb{R}^n$ dimensions into rectangles, cuboids or hyper cuboids. . What are we trying to do here? . This post/jupyter notebook is meant for visualising how the decision line for data in $ mathbb{R}^1$ space. . Approximated algorithm of Regression Decision Tree implemented here . Divide the dimension in $ mathbb{R}^1$ space into equally spaced intervals | At each interval compute the mean of all the points to the left and to the right of the interval | Compute the Mean Squared Error(MSE) of all the points to the left of the interval with respect to the mean obtained in step 2 and do the same respectively for the points to the right of the interval. | Add up the MSE&#39;s and keep track of them | Repeat steps 2 to 4 at all the intervals | Determine the interval where the MSE was minimum, this interval point is the optimal point which classifies the input data into two groups | Code start . Imports are handled and graph style presets are set here . import numpy as np import matplotlib.pyplot as plt from matplotlib import animation from IPython.display import Video %matplotlib widget plt.style.use(&#39;seaborn&#39;) . Helper functions to calculate the mean and mean squared error of data points . def mean(x, y, split_at): ml, mr = np.mean(y[x &lt; split_at]), np.mean(y[x &gt; split_at]) return ml, mr def mse(x, y, split_at, ml, mr): msel, mser = np.mean(np.square(ml - y[x &lt; split_at])), np.mean(np.square(mr - y[x &gt; split_at])) return msel, mser . Initialise random data. The data is generated using two normal distributions with their respective means and variances. Equal data points from each normal distribution are sampled. Here, a method is also declared to perform the repetitive steps 2 to 4 as per the above algorithm. . class Draw: def __init__(self, samples): &quot;&quot;&quot; Get the number of data samples to generate and prepare the figure &quot;&quot;&quot; self.fig = plt.figure() self.ax = self.fig.add_subplot(111) self.ax.set_xlabel(&#39;x&#39;) self.ax.set_ylabel(r&#39;$f(x)$&#39;) self.samples = samples # Data along the dimension of independent variable # 1st data cluster- mean=0, variance=0.1, count=samples/2 # 2nd data cluster- mean=0.7, variance=0.1, count=samples/2 self.x = np.hstack((np.random.normal(0, 0.1, (1, samples//2)), np.random.normal(0.7, 0.1, (1, samples//2)))) self.xmin = np.min(self.x) self.xmax = np.max(self.x) # Divide the search space along the independent variable x into equal intervals self.linspace = np.linspace(np.min(self.x), np.max(self.x), samples) # Data along the dimension of dependent variable(ex--&gt; Temperature over the day or year) # 1st data cluster- mean=0, variance=0.2, count=samples/2 # 2nd data cluster- mean=0.5, variance=0.2, count=samples/2 self.f = np.hstack((np.random.normal(0, 0.2, (1, samples//2)), np.random.normal(0.5, 0.2, (1, samples//2)))) self.fmax = np.max(self.f) self.mses = [] self.ax.scatter(self.x, self.f, marker= &#39;.&#39;) def step_tree(self, i): splitting_at = self.linspace[i+1] # self.ax.clear() for artist in plt.gca().lines + plt.gca().collections: artist.remove() left_mean, right_mean = mean(self.x, self.f, splitting_at) left_mse, right_mse = mse(self.x, self.f, splitting_at, left_mean, right_mean) self.mses.append(left_mse+right_mse) self.ax.scatter(self.x[self.x &lt; splitting_at], self.f[self.x &lt; splitting_at], c = &#39;c&#39;) self.ax.scatter(self.x[self.x &gt; splitting_at], self.f[self.x &gt; splitting_at], c = &#39;k&#39;) xllim, xrlim = self.ax.get_xlim() self.ax.axvline(splitting_at, 0, 1, c=&#39;r&#39;, linewidth=2) self.ax.axhline(left_mean, 0, (splitting_at-xllim)/(xrlim - xllim), c=&#39;c&#39;, linewidth=2, linestyle=&#39;-.&#39;, label=&#39;Left Mean&#39;) ymin = self.f.copy() ymax = ymin.copy() ymax[(self.x &lt; splitting_at) &amp; (self.f &lt; left_mean)] = left_mean ymin[(self.x &lt; splitting_at) &amp; (self.f &gt; left_mean)] = left_mean ymax[(self.x &gt; splitting_at) &amp; (self.f &lt; right_mean)] = right_mean ymin[(self.x &gt; splitting_at) &amp; (self.f &gt; right_mean)] = right_mean self.ax.vlines(self.x[(self.x &lt; splitting_at)], ymin[(self.x &lt; splitting_at)], ymax[(self.x &lt; splitting_at)], color=&#39;c&#39;, linestyle=&#39;--&#39;) self.ax.vlines(self.x[(self.x &gt; splitting_at)], ymin[(self.x &gt; splitting_at)], ymax[(self.x &gt; splitting_at)], color=&#39;k&#39;, linestyle=&#39;--&#39;) self.ax.axhline(right_mean, (splitting_at-xllim)/(xrlim - xllim), 1, c=&#39;k&#39;, linewidth=2, linestyle=&#39;-.&#39;, label=&#39;Right Mean&#39;) #print(len(self.linspace[:i+1]), len(self.mses)) self.ax.plot(self.linspace[:len(self.mses)], self.mses, c=&#39;r&#39;, label=&#39;MSE error&#39;) if i == self.samples-3: # self.ax.clear() for artist in plt.gca().lines + plt.gca().collections: artist.remove() self.ax.scatter(self.x[self.x &lt; self.linspace[np.argmin(self.mses)]], self.f[self.x &lt; self.linspace[np.argmin(self.mses)]], c = &#39;c&#39;, label=&#39;leaf-1 points&#39;) self.ax.scatter(self.x[self.x &gt; self.linspace[np.argmin(self.mses)]], self.f[self.x &gt; self.linspace[np.argmin(self.mses)]], c = &#39;k&#39;, label=&#39;leaf-2 points&#39;) self.ax.axhline(left_mean, 0, (self.linspace[np.argmin(self.mses)]-xllim)/(xrlim - xllim), c=&#39;c&#39;, linewidth=2, linestyle=&#39;-.&#39;, label=&#39;Left Mean&#39;) self.ax.axhline(right_mean, (self.linspace[np.argmin(self.mses)]-xllim)/(xrlim - xllim), 1, c=&#39;k&#39;, linewidth=2, linestyle=&#39;-.&#39;, label=&#39;Right Mean&#39;) self.ax.plot(self.linspace[:len(self.mses)], self.mses, c=&#39;r&#39;, label=&#39;MSE error&#39;) # self.ax.scatter(self.linspace[np.argmin(self.mses)], np.min(self.mses), c=&#39;g&#39;, marker=&#39;*&#39;, label=&#39;Minimum MSE&#39;) self.ax.axvline(self.linspace[np.argmin(self.mses)], c=&#39;b&#39;, label=&#39;Decision boundary at minimum MSE&#39;) self.ax.set_title(&#39;Decision boundary is at &#39;+str(self.linspace[np.argmin(self.mses)])) self.ax.legend(loc=&#39;upper left&#39;) . fps = 10 # frames per second samples = 50 # number of data samples assert samples % 2 == 0, &quot;Please specify an even number of data samples&quot; draw_obj = Draw(samples) Writer = animation.writers[&#39;ffmpeg&#39;] writer = Writer(fps=fps, metadata=dict(artist=&#39;Sai&#39;), bitrate=1800) animation.FuncAnimation(draw_obj.fig, draw_obj.step_tree, frames=samples-2, interval=(1/fps)*1000, repeat=False).save(&#39;decision_tree.mp4&#39;, writer=writer) . Video(&quot;../images/decision_tree/decision_tree.mp4&quot;, embed=True) . Your browser does not support the video tag. Results . As the algorithm progresses/steps through the equally spaced intervals we get to see how the means of left and right data points with respect to the interval position(red vertical line) varies and how this influence the MSE error. Finally we determine the interval where the mean was the minimum and hence choose this interval i.e. point along the independent variable x which divides the data into two sections. . The results of the entire operation is the final splitting boundary which determines wether it is either day or night, summer or winter and based on this independent variable x the decision tree enables us to take an educated guess about the possible temperature or any other possible value of f(x), which is nothing but the mean values of left and right leafs. .",
            "url": "https://logicatcore.github.io/scratchpad/machine%20learning/jupyter/2021/01/11/Regression-Decision-Tree.html",
            "relUrl": "/machine%20learning/jupyter/2021/01/11/Regression-Decision-Tree.html",
            "date": " • Jan 11, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Graphviz Artifical Neural Networks visualisation",
            "content": "Graphviz scripts to create simple visualisations of neural networks . Simple feed forward neural networks . Often while working with neural networks in Deep Learning and Machine Learning fields it is often easy to picturise the network architecture into a concise diagram which conveys lot of useful information. In what follows are some scripts that are inspired from martisak dotnets github repo including a rudementry graphing script which generates a DOT lannguage script interpretable by graphviz. The script found on the github repo was later ported to graphviz and expanded to add more functionalities to the script. The added functionalities enable activation function annotations and recurrent neural networks representation. . Firstly the graphviz module is imported and some global variables are set . try: import graphviz as G except ImportError as e: print(&#39;ModuleNotFoundError: &quot;graphviz&quot; package not available, install it with &quot;pip install graphviz&quot;&#39;) # boolean variables to denote dense or sparse connections between layers DENSE = True SPARSE = False PENWIDTH = &#39;15&#39; FONT = &#39;Hilda 10&#39; . Now the network architecture details are defined based on which a neural network will be graphed. The details include the number of nodes/perceptrons present in each layer, the type of connections between two layers. Since the connections are in-between layers, the length of connections list has to be 1 less than the length of layers list. . layer_nodes = [6, 4, 4, 4] connections = [DENSE, DENSE, SPARSE] assert len(connections) == (len(layer_nodes) - 1), &#39;&quot;connections&quot; array should be 1 less than the #layers&#39; for i, type_of_connections in enumerate(connections): if type_of_connections == SPARSE: assert layer_nodes[i] == layer_nodes[i+1], &quot;If connection type is SPARSE then the number of nodes in the adjacent layers must be equal&quot; . A graph in graphviz mainly consists of three components, namely, nodes, edges, and the graph itself. Just like defining a class while programming before creating an object, overhere the graphviz library provides a generic Digraph class which is to be instantiated with our desired object presets. The following piece of code instantiates a directed graph with some nodes, edges, and graph attributes based on which the graph will be drawn. . dot = G.Digraph(comment=&#39;Neural Network&#39;, graph_attr={&#39;nodesep&#39;:&#39;0.04&#39;, &#39;ranksep&#39;:&#39;0.05&#39;, &#39;bgcolor&#39;:&#39;white&#39;, &#39;splines&#39;:&#39;line&#39;, &#39;rankdir&#39;:&#39;LR&#39;, &#39;fontname&#39;:FONT}, node_attr={&#39;fixedsize&#39;:&#39;true&#39;, &#39;label&#39;:&quot;&quot;, &#39;style&#39;:&#39;filled&#39;, &#39;color&#39;:&#39;none&#39;, &#39;fillcolor&#39;:&#39;gray&#39;, &#39;shape&#39;:&#39;circle&#39;, &#39;penwidth&#39;:PENWIDTH, &#39;width&#39;:&#39;0.4&#39;, &#39;height&#39;:&#39;0.4&#39;}, edge_attr={&#39;color&#39;:&#39;gray30&#39;, &#39;arrowsize&#39;:&#39;.4&#39;}) . Create nodes . for layer_no in range(len(layer_nodes)): with dot.subgraph(name=&#39;cluster_&#39;+str(layer_no)) as c: c.attr(color=&#39;transparent&#39;) # comment this if graph background is needed if layer_no == 0: # first layer c.attr(label=&#39;Input&#39;) elif layer_no == len(layer_nodes)-1: # last layer c.attr(label=&#39;Output&#39;) else: # layers in between c.attr(label=&#39;Hidden&#39;) for a in range(layer_nodes[layer_no]): if layer_no == 0: # or i == len(layers)-1: # first or last layer c.node(&#39;l&#39;+str(layer_no)+str(a), &#39;&#39;, fillcolor=&#39;black&#39;)#, fontcolor=&#39;white&#39; if layer_no == len(layer_nodes)-1: c.node(&#39;l&#39;+str(layer_no)+str(a), &#39;&#39;, fontcolor=&#39;white&#39;, fillcolor=&#39;black&#39;)#, fontcolor=&#39;white&#39; else: # unicode characters can be used to inside the nodes as follows # for a list of unicode characters refer this https://pythonforundergradengineers.com/unicode-characters-in-python.html c.node(&#39;l&#39;+str(layer_no)+str(a), &#39; u03C3&#39;, fontsize=&#39;12&#39;) # to place &quot;sigma&quot; inside the nodes of a layer # for normal textual representation like &#39;relu&#39; and &#39;tanh&#39;, the following approach can be taken # c.node(&#39;l&#39;+str(layer_no)+str(a), &#39;relu&#39;, fontsize=&#39;12&#39;) . Create edges . for layer_no in range(len(layer_nodes)-1): for node_no in range(layer_nodes[layer_no]): if connections[layer_no] == DENSE: for b in range(layer_nodes[layer_no+1]): dot.edge(&#39;l&#39;+str(layer_no)+str(node_no), &#39;l&#39;+str(layer_no+1)+str(b),) elif connections[layer_no] == SPARSE: dot.edge(&#39;l&#39;+str(layer_no)+str(node_no), &#39;l&#39;+str(layer_no+1)+str(node_no)) . Render . dot . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_0 Input cluster_1 Hidden cluster_2 Hidden cluster_3 Output l00 σ l10 σ l00&#45;&gt;l10 l11 σ l00&#45;&gt;l11 l12 σ l00&#45;&gt;l12 l13 σ l00&#45;&gt;l13 l01 σ l01&#45;&gt;l10 l01&#45;&gt;l11 l01&#45;&gt;l12 l01&#45;&gt;l13 l02 σ l02&#45;&gt;l10 l02&#45;&gt;l11 l02&#45;&gt;l12 l02&#45;&gt;l13 l03 σ l03&#45;&gt;l10 l03&#45;&gt;l11 l03&#45;&gt;l12 l03&#45;&gt;l13 l04 σ l04&#45;&gt;l10 l04&#45;&gt;l11 l04&#45;&gt;l12 l04&#45;&gt;l13 l05 σ l05&#45;&gt;l10 l05&#45;&gt;l11 l05&#45;&gt;l12 l05&#45;&gt;l13 l20 σ l10&#45;&gt;l20 l21 σ l10&#45;&gt;l21 l22 σ l10&#45;&gt;l22 l23 σ l10&#45;&gt;l23 l11&#45;&gt;l20 l11&#45;&gt;l21 l11&#45;&gt;l22 l11&#45;&gt;l23 l12&#45;&gt;l20 l12&#45;&gt;l21 l12&#45;&gt;l22 l12&#45;&gt;l23 l13&#45;&gt;l20 l13&#45;&gt;l21 l13&#45;&gt;l22 l13&#45;&gt;l23 l30 l20&#45;&gt;l30 l31 l21&#45;&gt;l31 l32 l22&#45;&gt;l32 l33 l23&#45;&gt;l33 Save/Export . dot.format = &#39;JPEG&#39; # or PDF, SVG, JPEG, PNG, etc. . dot.render(&#39;./example_network&#39;) . &#39;./example_network.jpeg&#39; . Recurrent neural network . The previously used code can be modified and adapted easily for variuous architectures, for adding additional details, for customizing, and much more. The same code if now modified to represent recurrent neural networks instead. . layer_nodes = [6, 4, 4, 4] connections = [DENSE, DENSE, DENSE] # additional variable to denote which layers consist of recurrent units recurrent = [False, True, True, False] assert len(connections) == (len(layer_nodes) - 1), &#39;&quot;connections&quot; array should be 1 less than the #layers&#39; for i, type_of_connections in enumerate(connections): if type_of_connections == SPARSE: assert layer_nodes[i] == layer_nodes[i+1], &quot;If connection type is SPARSE then the number of nodes in the adjacent layers must be equal&quot; dot = G.Digraph(comment=&#39;Neural Network&#39;, graph_attr={&#39;nodesep&#39;:&#39;0.04&#39;, &#39;ranksep&#39;:&#39;0.05&#39;, &#39;bgcolor&#39;:&#39;white&#39;, &#39;splines&#39;:&#39;line&#39;, &#39;rankdir&#39;:&#39;LR&#39;, &#39;fontname&#39;:FONT}, node_attr={&#39;fixedsize&#39;:&#39;true&#39;, &#39;label&#39;:&quot;&quot;, &#39;style&#39;:&#39;filled&#39;, &#39;color&#39;:&#39;none&#39;, &#39;fillcolor&#39;:&#39;gray&#39;, &#39;shape&#39;:&#39;circle&#39;, &#39;penwidth&#39;:PENWIDTH, &#39;width&#39;:&#39;0.4&#39;, &#39;height&#39;:&#39;0.4&#39;}, edge_attr={&#39;color&#39;:&#39;gray30&#39;, &#39;arrowsize&#39;:&#39;.4&#39;}) for layer_no in range(len(layer_nodes)): with dot.subgraph(name=&#39;cluster_&#39;+str(layer_no)) as c: c.attr(color=&#39;transparent&#39;) # comment this if graph background is needed if layer_no == 0: # first layer c.attr(label=&#39;Input&#39;) elif layer_no == len(layer_nodes)-1: # last layer c.attr(label=&#39;Output&#39;) else: # layers in between c.attr(label=&#39;Hidden&#39;) for a in range(layer_nodes[layer_no]): if layer_no == 0: # or i == len(layers)-1: # first or last layer c.node(&#39;l&#39;+str(layer_no)+str(a), &#39;&#39;, fillcolor=&#39;black&#39;)#, fontcolor=&#39;white&#39; if layer_no == len(layer_nodes)-1: c.node(&#39;l&#39;+str(layer_no)+str(a), &#39;&#39;, fontcolor=&#39;white&#39;, fillcolor=&#39;black&#39;)#, fontcolor=&#39;white&#39; else: # unicode characters can be used to inside the nodes as follows # for a list of unicode characters refer this https://pythonforundergradengineers.com/unicode-characters-in-python.html # c.node(&#39;l&#39;+str(layer_no)+str(a), &#39; u03C3&#39;, fontsize=&#39;12&#39;) # to place &quot;sigma&quot; inside the nodes of a layer # for normal textual representation like &#39;relu&#39; and &#39;tanh&#39;, the following approach can be taken c.node(&#39;l&#39;+str(layer_no)+str(a), &#39;tanh&#39;, fontsize=&#39;12&#39;) for layer_no in range(len(layer_nodes)-1): for node_no in range(layer_nodes[layer_no]): if connections[layer_no] == DENSE: # to place recuurent units # change the label &#39;x10&#39; to denote the number of time steps into which the recurrent unit unrolls in time if recurrent[layer_no]: dot.edge(&#39;l&#39;+str(layer_no)+str(node_no), &#39;l&#39;+str(layer_no)+str(node_no), xlabel=&#39;x10&#39;, color=&#39;blue&#39;, fontcolor=&#39;blue&#39;) for b in range(layer_nodes[layer_no+1]): dot.edge(&#39;l&#39;+str(layer_no)+str(node_no), &#39;l&#39;+str(layer_no+1)+str(b),) elif connections[layer_no] == SPARSE: dot.edge(&#39;l&#39;+str(layer_no)+str(node_no), &#39;l&#39;+str(layer_no+1)+str(node_no)) . dot . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_0 Input cluster_1 Hidden cluster_2 Hidden cluster_3 Output l00 tanh l10 tanh l00&#45;&gt;l10 l11 tanh l00&#45;&gt;l11 l12 tanh l00&#45;&gt;l12 l13 tanh l00&#45;&gt;l13 l01 tanh l01&#45;&gt;l10 l01&#45;&gt;l11 l01&#45;&gt;l12 l01&#45;&gt;l13 l02 tanh l02&#45;&gt;l10 l02&#45;&gt;l11 l02&#45;&gt;l12 l02&#45;&gt;l13 l03 tanh l03&#45;&gt;l10 l03&#45;&gt;l11 l03&#45;&gt;l12 l03&#45;&gt;l13 l04 tanh l04&#45;&gt;l10 l04&#45;&gt;l11 l04&#45;&gt;l12 l04&#45;&gt;l13 l05 tanh l05&#45;&gt;l10 l05&#45;&gt;l11 l05&#45;&gt;l12 l05&#45;&gt;l13 l10&#45;&gt;l10 x10 l20 tanh l10&#45;&gt;l20 l21 tanh l10&#45;&gt;l21 l22 tanh l10&#45;&gt;l22 l23 tanh l10&#45;&gt;l23 l11&#45;&gt;l11 x10 l11&#45;&gt;l20 l11&#45;&gt;l21 l11&#45;&gt;l22 l11&#45;&gt;l23 l12&#45;&gt;l12 x10 l12&#45;&gt;l20 l12&#45;&gt;l21 l12&#45;&gt;l22 l12&#45;&gt;l23 l13&#45;&gt;l13 x10 l13&#45;&gt;l20 l13&#45;&gt;l21 l13&#45;&gt;l22 l13&#45;&gt;l23 l20&#45;&gt;l20 x10 l30 l20&#45;&gt;l30 l31 l20&#45;&gt;l31 l32 l20&#45;&gt;l32 l33 l20&#45;&gt;l33 l21&#45;&gt;l21 x10 l21&#45;&gt;l30 l21&#45;&gt;l31 l21&#45;&gt;l32 l21&#45;&gt;l33 l22&#45;&gt;l22 x10 l22&#45;&gt;l30 l22&#45;&gt;l31 l22&#45;&gt;l32 l22&#45;&gt;l33 l23&#45;&gt;l23 x10 l23&#45;&gt;l30 l23&#45;&gt;l31 l23&#45;&gt;l32 l23&#45;&gt;l33 Save/Export . dot.format = &#39;pdf&#39; # or PDF, SVG, JPEG, PNG, etc. . dot.render(&#39;./example_recurrent_network&#39;) . &#39;./example_recurrent_network.pdf&#39; . Some more additional scripts that are useful . 1.Unrolled representation of a single recurrent unit . TIMESTEPS = 6 TIME_OFFSET = 3 unrolled = G.Digraph(node_attr={&#39;shape&#39;:&#39;circle&#39;, &#39;fixedsize&#39;:&#39;true&#39;}, graph_attr={&#39;style&#39;:&#39;invis&#39;, &#39;rankdir&#39;:&#39;BT&#39;, &#39;color&#39;:&#39;transparent&#39;}) . for step in range(TIMESTEPS+2): if step == 0 or step == TIMESTEPS+1: with unrolled.subgraph(name=&#39;cluster_&#39;+str(i)) as c: c.node(&#39;a&#39;+str(step), &#39;&#39;, color=&#39;transparent&#39;) c.node(&#39;b&#39;+str(step), &#39;...&#39;, color=&#39;transparent&#39;) c.node(&#39;c&#39;+str(step), &#39;&#39;, color=&#39;transparent&#39;) c.edge(&#39;a&#39;+str(step), &#39;b&#39;+str(step), style=&#39;invis&#39;) c.edge(&#39;b&#39;+str(step), &#39;c&#39;+str(step), style=&#39;invis&#39;) else: with unrolled.subgraph(name=&#39;cluster_&#39;+str(i)) as c: c.node(&#39;a&#39;+str(step), &#39;&#39;, color=&#39;transparent&#39;) c.node(&#39;b&#39;+str(step), &#39;t&#39;+&#39;{:=+d}&#39;.format(TIME_OFFSET-step) if TIME_OFFSET-step else &#39;t&#39;) c.node(&#39;c&#39;+str(step), &#39;&#39;, color=&#39;transparent&#39;); c.edge(&#39;a&#39;+str(step), &#39;b&#39;+str(step)); c.edge(&#39;b&#39;+str(step), &#39;c&#39;+str(step)); . for step in range(1, TIMESTEPS+2): unrolled.edge(&#39;b&#39;+str(step-1), &#39;b&#39;+str(step), constraint=&#39;false&#39;, dir=&#39;back&#39;, color=&#39;blue&#39;) . unrolled . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster_2 a0 b0 ... c0 b1 t+2 b0&#45;&gt;b1 a1 a1&#45;&gt;b1 c1 b1&#45;&gt;c1 b2 t+1 b1&#45;&gt;b2 a2 a2&#45;&gt;b2 c2 b2&#45;&gt;c2 b3 t b2&#45;&gt;b3 a3 a3&#45;&gt;b3 c3 b3&#45;&gt;c3 b4 t&#45;1 b3&#45;&gt;b4 a4 a4&#45;&gt;b4 c4 b4&#45;&gt;c4 b5 t&#45;2 b4&#45;&gt;b5 a5 a5&#45;&gt;b5 c5 b5&#45;&gt;c5 b6 t&#45;3 b5&#45;&gt;b6 a6 a6&#45;&gt;b6 c6 b6&#45;&gt;c6 b7 ... b6&#45;&gt;b7 a7 c7 unrolled.render(&#39;./unrolled&#39;) . &#39;./unrolled.pdf&#39; . 2.Single recurrent unit . ru = G.Digraph(node_attr={&#39;shape&#39;:&#39;circle&#39;, &#39;fixedsize&#39;:&#39;true&#39;}, graph_attr={&#39;style&#39;:&#39;invis&#39;, &#39;rankdir&#39;:&#39;LR&#39;}) . ru.node(&#39;a&#39;, &#39;&#39;, color=&#39;transparent&#39;) ru.node(&#39;b&#39;, &#39;N&#39;) ru.node(&#39;c&#39;, &#39;&#39;, color=&#39;transparent&#39;) ru.edge(&#39;a&#39;, &#39;b&#39;) ru.edge(&#39;b&#39;, &#39;c&#39;) ru.edge(&#39;b&#39;, &#39;b&#39;, color=&#39;blue&#39;) . ru . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 a b N a&#45;&gt;b b&#45;&gt;b c b&#45;&gt;c ru.render(&#39;./rnn&#39;) . &#39;./rnn.pdf&#39; .",
            "url": "https://logicatcore.github.io/scratchpad/machine%20learning/jupyter/graphviz/2020/12/26/Graphviz-Neural-Networks-visualisation.html",
            "relUrl": "/machine%20learning/jupyter/graphviz/2020/12/26/Graphviz-Neural-Networks-visualisation.html",
            "date": " • Dec 26, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Input data representation as 2D array of 3D blocks",
            "content": ". Often while working with machine learning algorithms the developer has a good picture of how the input data looks like apart from knowing what the input data is. Also, most of the times the input data is usually represented or decribed with array terminology. Hence, this particular post is one such attempt to create simple 2D representations of 3D-blocks symbolising the arrays used for input. . Graphviz a highly versatile graphing library that creates graphs based on DOT language is used to create the 2D array representation of 3D blocks with annotation and color uniformity to create quick and concise graphs/pictures for good explanations of input data used in various machine learning/deep learning algorithms. . In what follows is a script to create the 2D array representation og 3D blocks mainly intented for time-series data. The script facilitates some features which include- . Starting at time instant 0 or -1 | counting backwards i.e. t-4 -&gt; t-3 -&gt; t-2 -&gt; t-1 -&gt; t-0 or counting forwards t-0 -&gt; t-1 -&gt; t-2 -&gt; t-3 -&gt; t-4 -&gt; t-5 | . Imports and global constants . import graphviz as G # to create the required graphs import random # to generate random hex codes for colors FORWARDS = True # to visualise array from left to right BACKWARDS = False # to visualise array from right to left . Properties of 2D representation of 3D array blocks . Main features/properties of the array visualisation needed are defined gere before actually creating the graph/picture. 1) Number of Rows: similar to rows in a matrix where each each row corresponds to one particular data type with data across different time instants arranged in columns . 2) Blocks: which corresponds to the number of time instants in each row (jagged arrays can also be graphed) . 3) Prefix: the annotation used to annotate each 3D block in the 2D array representation . ROW_NUMS = [1, 2] # Layer numbers corresponding to the number of rows of array data (must be contiguous) BLOCKS = [3, 3] # number of data fields in each row i.e., columns in each row diff = [x - ROW_NUMS[i] for i, x in enumerate(ROW_NUMS[1:])] assert diff == [1]*(len(ROW_NUMS) - 1), &#39;&quot;layer_num&quot; should contain contiguous numbers only&#39; assert len(ROW_NUMS) == len(BLOCKS), &quot;&#39;cells&#39; list and &#39;layer_num&#39; list should contain same number of entries&quot; direction = BACKWARDS # control the direction of countdown of timesteps INCLUDE_ZERO = True # for time series based data START_AT = 0 if INCLUDE_ZERO else 1 # names = [[&#39;Softmax nprobabilities&#39;, &#39;p1&#39;, &#39;p2&#39;, &#39;p3&#39;, &#39;p4&#39;, &#39;p5&#39;, &#39;p6&#39;, &#39;p7&#39;, &#39;p8&#39;, &#39;p9&#39;, &#39;p10&#39;],[&#39;&#39;, &#39; +&#39;, &#39; +&#39;, &#39; +&#39;, &#39; +&#39;, &#39; +&#39;, &#39; +&#39;],[&#39;GMM nprobabilities&#39;, &#39;p1&#39;, &#39;p2&#39;, &#39;p3&#39;, &#39;p4&#39;, &#39;p5&#39;, &#39;p6&#39;]] # the trick to adding symbols like the &quot;partial(dou)&quot; i.e. &#39;∂&#39; is to write these symbols in a markdown cell using the $ partial$ utilising the mathjax support and # copying the content after being rendered and paste in the code as a string wherever needed prefix = [&#39;∂(i)-&#39;, &#39;∂(v)-&#39;] . r = lambda: random.randint(0,255) # to generate random colors for each row # intantiate a directed graph with intial properties dot = G.Digraph(comment=&#39;Matrix&#39;, graph_attr={&#39;nodesep&#39;:&#39;0.02&#39;, &#39;ranksep&#39;:&#39;0.02&#39;, &#39;bgcolor&#39;:&#39;transparent&#39;}, node_attr={&#39;shape&#39;:&#39;box3d&#39;,&#39;fixedsize&#39;:&#39;true&#39;, &#39;width&#39;:&#39;1.1&#39;}) for row_no in ROW_NUMS: if row_no != 1: dot.edge(str(row_no-1)+str(START_AT), str(row_no)+str(START_AT), style=&#39;invis&#39;) # invisible edges to contrain layout with dot.subgraph() as sg: sg.attr(rank=&#39;same&#39;) color = &#39;#{:02x}{:02x}{:02x}&#39;.format(r(),r(),r()) for block_no in range(START_AT, BLOCKS[row_no-1]+START_AT): if direction: sg.node(str(row_no)+str(block_no), &#39;t-&#39;+str(block_no), style=&#39;filled&#39;, fillcolor=color) else: if START_AT == 0: sg.node(str(row_no)+str(block_no), prefix[row_no-1]+str(BLOCKS[row_no-1]-block_no-1), style=&#39;filled&#39;, fillcolor=color) else: sg.node(str(row_no)+str(block_no), prefix[row_no-1]+str(BLOCKS[row_no-1]-block_no-1), style=&#39;filled&#39;, fillcolor=color) . Render . dot . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 10 ∂(i)&#45;2 20 ∂(v)&#45;2 11 ∂(i)&#45;1 12 ∂(i)&#45;0 21 ∂(v)&#45;1 22 ∂(v)&#45;0 Save/Export . . dot.render(&#39;./lstm_input&#39;) . &#39;./lstm_input.pdf&#39; . Additional script to just show the breakdown of train-test data of the dataset being used . import random r = lambda: random.randint(0,255) # to generate random colors for each row . folders = G.Digraph(node_attr={&#39;style&#39;:&#39;filled&#39;}, graph_attr={&#39;style&#39;:&#39;invis&#39;, &#39;rankdir&#39;:&#39;LR&#39;},edge_attr={&#39;color&#39;:&#39;black&#39;, &#39;arrowsize&#39;:&#39;.2&#39;}) . color = &#39;#{:02x}{:02x}{:02x}&#39;.format(r(),r(),r()) with folders.subgraph(name=&#39;cluster0&#39;) as f: f.node(&#39;root&#39;, &#39;Dataset n x2000&#39;, shape=&#39;folder&#39;, fillcolor=color) . color = &#39;#{:02x}{:02x}{:02x}&#39;.format(r(),r(),r()) with folders.subgraph(name=&#39;cluster1&#39;) as f: f.node(&#39;train&#39;, &#39;Train n 1800&#39;, shape=&#39;note&#39;, fillcolor=color) f.node(&#39;test&#39;, &#39;Test n x200&#39;, shape=&#39;note&#39;, fillcolor=color) . folders.edge(&#39;root&#39;, &#39;train&#39;) folders.edge(&#39;root&#39;, &#39;test&#39;) . folders . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster0 cluster1 root Dataset x2000 train Train 1800 root&#45;&gt;train test Test x200 root&#45;&gt;test folders.render(&#39;./dataset&#39;) . &#39;./dataset.pdf&#39; .",
            "url": "https://logicatcore.github.io/scratchpad/machine%20learning/jupyter/graphviz/2020/12/26/Array-Visualiser.html",
            "relUrl": "/machine%20learning/jupyter/graphviz/2020/12/26/Array-Visualiser.html",
            "date": " • Dec 26, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Optimization algorithms using pytorch",
            "content": "Optimization algorithms using pytorch . Optimization algorithms play a central role in the learning process of most of the machine learning and deep learning algorithms. Here are some of the well known algorithms- . Vanilla Gradient descent | Gradient descent with Momentum | RMSprop | Adam | While all the 4 above listed algorithms differ in their own way and have certain advantages and disadvantages. They share certain similarities with the simple graddient descent algorithm. In this blog post we will go through these 4 algorithms and see how they function on minimizing the loss or finding the minima of a random error function with multiple minimas and maximas implemented using pytorch. . Error function with multiple minimas and maximas . Error Function $= f(x,y) = 3 times e^{(-(y + 1)^2 - x^2)} times (x - 1)^2 - frac{e^{(-(x + 1)^2 - y^2)}}{3} + e^{(-x^2 - y^2)} times (10x^3 - 2x + 10y^5)$ . . Note: In this blog post, I will not be going into the theory of all the algorithms used rather just concentrate on the implementation and the results . For theoretical reference please refer to d2lai chapter on optimization algorithms . Import all the necessary python modules . %matplotlib widget import torch import IPython import numpy as np from IPython import display from IPython.display import HTML, Video import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib import animation from mpl_toolkits.mplot3d import Axes3D from mpl_toolkits.mplot3d import proj3d from matplotlib.patches import FancyArrowPatch # mpl.rcParams[&#39;savefig.dpi&#39;] = 300 plt.style.use(&#39;seaborn&#39;) . To draw arrows to monitor the progress of optimization . class Arrow3D(FancyArrowPatch): def __init__(self, xs, ys, zs, *args, **kwargs): FancyArrowPatch.__init__(self, (0, 0), (0, 0), *args, **kwargs) self._verts3d = xs, ys, zs def draw(self, renderer): xs3d, ys3d, zs3d = self._verts3d xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M) self.set_positions((xs[0], ys[0]), (xs[1], ys[1])) FancyArrowPatch.draw(self, renderer) . Error or loss calculation based on 2 independent parameters . def calc_z(xx, yy)-&gt; torch.tensor: &quot;&quot;&quot; Returns the loss at a certain point &quot;&quot;&quot; return 3 * torch.exp(-(yy + 1) ** 2 - xx ** 2) * (xx - 1) ** 2 - torch.exp(-(xx + 1) ** 2 - yy ** 2) / 3 + torch.exp( -xx ** 2 - yy ** 2) * (10 * xx ** 3 - 2 * xx + 10 * yy ** 5) . fps = 10 # frames per second - to save the progress in optimization as a video Writer = animation.writers[&#39;ffmpeg&#39;] writer = Writer(fps=fps, metadata=dict(artist=&#39;Me&#39;), bitrate=1800) . Initialise the plot with the error function terrain . x = torch.linspace(-3, 3, 600) y = torch.linspace(-3, 3, 600) xgrid, ygrid = torch.meshgrid(x, y) zgrid = calc_z(xgrid, ygrid) fig = plt.figure(figsize=(14,6)) ax0 = fig.add_subplot(121, projection=&#39;3d&#39;) ax0.set_xlabel(&#39;$x$&#39;) ax0.set_ylabel(&#39;$y$&#39;) ax0.set_zlabel(&#39;Random Loss function: &#39; + &#39;$f(x, y)$&#39;) ax0.axis(&#39;auto&#39;) cs = ax0.plot_surface(xgrid.numpy(), ygrid.numpy(), zgrid.numpy(), cmap=&#39;viridis&#39;, alpha=0.6) fig.colorbar(cs) ax1 = fig.add_subplot(122) qcs = ax1.contour(xgrid.numpy(), ygrid.numpy(), zgrid.numpy(), 20, cmap=&#39;viridis&#39;) fig.colorbar(qcs) . &lt;matplotlib.colorbar.Colorbar at 0x7f7dccd822b0&gt; . . Vanilla Gradient Descent . Gradient descent algorithm which is an iterative optimization algorithm can be described as loop which is executed repeatedly until certain convergence criteria has been met. Gradient descent can be explained using the following equation. . Gradient calculation . $ frac{ partial (Error)}{ partial (w_{x,y}^l)} = begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix}$ . Update equation . $w_{x,y}^l = w_{x,y}^l - lr times frac{ partial (Error)}{ partial (w_{x,y}^l)}$ . epochs = 20 lr = 0.01 # learning rate xys = torch.tensor([-0.5, -0.7], requires_grad=True) # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) new_z = 0 dy_dx_current = 0 . def step_gd(i): global dy_dx_current, xys, lr, new_z, ax0, ax1 if i == 0: # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) xys = torch.tensor([-0.5, -0.7], requires_grad=True) new_z = calc_z(xys[0], xys[1]) new_z.backward() dy_dx_current = xys.grad cache_pt = [xys[0].detach().numpy(), xys[1].detach().numpy(), new_z.detach().numpy()] xys = (xys - lr * dy_dx_current).clone().detach().requires_grad_(True) # vanilla gradient descent new_z = calc_z(xys[0], xys[1]) new_z.backward() # store the new gradient with respect to x and y i.e., (d(error))/ (dx), (d(error))/ (dy) dy_dx_current = xys.grad xys_plot = xys.detach().numpy() ax0.scatter(xys_plot[0], xys_plot[1], new_z.detach().numpy(), marker=&#39;s&#39;, c=&#39;r&#39;, s=20, zorder=3) a = Arrow3D([cache_pt[0], xys_plot[0]], [cache_pt[1], xys_plot[1]], [cache_pt[2], new_z.detach().numpy()], mutation_scale=5, lw=2, arrowstyle=&quot;-|&gt;&quot;, color=&quot;k&quot;) ax0.add_artist(a) ax1.scatter(xys_plot[0], xys_plot[1], marker=&#39;*&#39;, c=&#39;r&#39;) . anim_gd = animation.FuncAnimation(fig, step_gd, frames=epochs, interval=(1/fps)*1000, repeat=False) . anim_gd.save(&#39;gd.mp4&#39;, writer=writer) . Video(&quot;../images/optimization_algos/gd.mp4&quot;, embed=True) . Your browser does not support the video tag. Gradient descent with momentum . Gradient calculation . $ frac{ partial (Error)}{ partial (w_{x,y}^l)} = begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} = beta * begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} + (1 - beta) * begin{vmatrix} frac{ partial (Error_{new})}{ partial x} frac{ partial (Error_{new})}{ partial y} end{vmatrix}$ . Update equation . $w_{x,y}^l = w_{x,y}^l - lr times frac{ partial (Error)}{ partial (w_{x,y}^l)}$ . epochs = 60 lr = 0.01 # learning rate xys = torch.tensor([-0.5, -0.7], requires_grad=True) # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) new_z = 0 dy_dx_current_gdm = 0 dy_dx_new_gdm = torch.tensor([0.0, 0.0]) . def step_gdm(i): global dy_dx_new_gdm, dy_dx_current_gdm, xys, lr, new_z, ax0, ax1 if i == 0: # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) xys = torch.tensor([-0.5, -0.7], requires_grad=True) new_z = calc_z(xys[0], xys[1]) new_z.backward() dy_dx_current_gdm = xys.grad cache_pt = [xys[0].detach().numpy(), xys[1].detach().numpy(), new_z.detach().numpy()] dy_dx_new_gdm = 0.9*dy_dx_new_gdm + (1 - 0.9)*dy_dx_current_gdm xys = (xys - lr * dy_dx_new_gdm).clone().detach().requires_grad_(True) # gradient descent with momentum new_z = calc_z(xys[0], xys[1]) new_z.backward() # store the new gradient with respect to x and y i.e., (d(error))/ (dx), (d(error))/ (dy) dy_dx_current_gdm = xys.grad xys_plot = xys.detach().numpy() ax0.scatter(xys_plot[0], xys_plot[1], new_z.detach().numpy(), marker=&#39;s&#39;, c=&#39;g&#39;, s=20, zorder=3) a = Arrow3D([cache_pt[0], xys_plot[0]], [cache_pt[1], xys_plot[1]], [cache_pt[2], new_z.detach().numpy()], mutation_scale=5, lw=2, arrowstyle=&quot;-|&gt;&quot;, color=&quot;k&quot;) ax0.add_artist(a) ax1.scatter(xys_plot[0], xys_plot[1], marker=&#39;*&#39;, c=&#39;g&#39;) . anim_gdm = animation.FuncAnimation(fig, step_gdm, frames=epochs, interval=(1/fps)*1000, repeat=False) . anim_gdm.save(&#39;momentum.mp4&#39;, writer=writer) . Video(&quot;../images/optimization_algos/momentum.mp4&quot;, embed=True) . Your browser does not support the video tag. RMSprop . Gradient calculation . $ frac{ partial (Error)}{ partial (w_{x,y}^l)} = begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} = beta * begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} + (1 - beta) * begin{vmatrix} frac{ partial (Error_{new})}{ partial x} frac{ partial (Error_{new})}{ partial y} end{vmatrix}^2$ . Update equation . $w_{x,y}^l = w_{x,y}^l - lr times frac{ frac{ partial (Error_{new})}{ partial (w_{x,y}^l)}}{ sqrt{ frac{ partial (Error)}{ partial (w_{x,y}^l)} + epsilon}}$ . epochs = 150 rmsprop_lr = 0.01 # learning rate xys = torch.tensor([-0.5, -0.7], requires_grad=True) # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) epsilon = 1e-7 # small constant to avoid division by zero new_z = 0 dy_dx_current_rmsprop = 0 dy_dx_new_rmsprop = torch.tensor([0.0, 0.0]) . def step_rmsprop(i): global dy_dx_new_rmsprop, dy_dx_current_rmsprop, xys, rmsprop_lr, new_z, ax0, ax1 if i == 0: # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) xys = torch.tensor([-0.5, -0.7], requires_grad=True) new_z = calc_z(xys[0], xys[1]) new_z.backward() dy_dx_current_rmsprop = xys.grad cache_pt = [xys[0].detach().numpy(), xys[1].detach().numpy(), new_z.detach().numpy()] dy_dx_new_rmsprop = 0.9*dy_dx_new_rmsprop + (1 - 0.9)*torch.pow(dy_dx_current_rmsprop,2) xys = (xys - rmsprop_lr * (dy_dx_current_rmsprop/(torch.sqrt(dy_dx_new_rmsprop) + epsilon))).clone().detach().requires_grad_(True) # gradient descent with momentum new_z = calc_z(xys[0], xys[1]) new_z.backward() # store the new gradient with respect to x and y i.e., (d(error))/ (dx), (d(error))/ (dy) dy_dx_current_rmsprop = xys.grad xys_plot = xys.detach().numpy() ax0.scatter(xys_plot[0], xys_plot[1], new_z.detach().numpy(), marker=&#39;s&#39;, c=&#39;b&#39;, s=20, zorder=3) a = Arrow3D([cache_pt[0], xys_plot[0]], [cache_pt[1], xys_plot[1]], [cache_pt[2], new_z.detach().numpy()], mutation_scale=5, lw=2, arrowstyle=&quot;-|&gt;&quot;, color=&quot;k&quot;) ax0.add_artist(a) ax1.scatter(xys_plot[0], xys_plot[1], marker=&#39;*&#39;, c=&#39;b&#39;) . anim_rmsprop = animation.FuncAnimation(fig, step_rmsprop, frames=epochs, interval=(1/fps)*1000, repeat=False) . anim_rmsprop.save(&#39;rmsprop.mp4&#39;, writer=writer) . Video(&quot;../images/optimization_algos/rmsprop.mp4&quot;, embed=True) . Your browser does not support the video tag. Adam . Gradient calculation . ${ partial (Error)}_{momentum} = frac{ partial (Error)}{ partial (w_{x,y}^l)} = begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} = beta_1 * begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} + (1 - beta_1) * begin{vmatrix} frac{ partial (Error_{new})}{ partial x} frac{ partial (Error_{new})}{ partial y} end{vmatrix}$ . ${ partial (Error)}_{rmsprop} = frac{ partial (Error)}{ partial (w_{x,y}^l)} = begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} = beta_2 * begin{vmatrix} frac{ partial (Error)}{ partial x} frac{ partial (Error)}{ partial y} end{vmatrix} + (1 - beta_2) * begin{vmatrix} frac{ partial (Error_{new})}{ partial x} frac{ partial (Error_{new})}{ partial y} end{vmatrix}^2$ . Update equation . $w_{x,y}^l = w_{x,y}^l - lr times frac{ partial (Error)_{momentum}}{ sqrt{ partial (Error)_{rmsprop}} + epsilon}$ . epochs = 240 adam_lr = 0.01 # learning rate xys = torch.tensor([-0.5, -0.7], requires_grad=True) # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) epsilon = 1e-7 # small constant to avoid division by zero new_z = 0 dy_dx_current_mom = 0 dy_dx_current_rmsprop = 0 dy_dx_new = torch.tensor([0.0, 0.0]) . def step_adam(i): global dy_dx_current_mom, dy_dx_current_rmsprop, dy_dx_new, xys, adam_lr, new_z, ax0, ax1 if i == 0: # initialise starting point of search for minima, another possible starting position np.array([0.1, 1.4]) xys = torch.tensor([-0.5, -0.7], requires_grad=True) new_z = calc_z(xys[0], xys[1]) new_z.backward() dy_dx_new = xys.grad cache_pt = [xys[0].detach().numpy(), xys[1].detach().numpy(), new_z.detach().numpy()] dy_dx_current_mom = 0.9*dy_dx_current_mom + (1 - 0.9)*dy_dx_new dy_dx_current_rmsprop = 0.9*dy_dx_current_rmsprop + (1 - 0.9)*torch.pow(dy_dx_new,2) xys = (xys - adam_lr * (dy_dx_current_mom/(torch.sqrt(dy_dx_current_rmsprop) + epsilon))).clone().detach().requires_grad_(True) # gradient descent with momentum new_z = calc_z(xys[0], xys[1]) new_z.backward() # store the new gradient with respect to x and y i.e., (d(error))/ (dx), (d(error))/ (dy) dy_dx_new = xys.grad xys_plot = xys.detach().numpy() ax0.scatter(xys_plot[0], xys_plot[1], new_z.detach().numpy(), marker=&#39;s&#39;, c=&#39;c&#39;, s=20, zorder=3) a = Arrow3D([cache_pt[0], xys_plot[0]], [cache_pt[1], xys_plot[1]], [cache_pt[2], new_z.detach().numpy()], mutation_scale=5, lw=2, arrowstyle=&quot;-|&gt;&quot;, color=&quot;k&quot;) ax0.add_artist(a) ax1.scatter(xys_plot[0], xys_plot[1], marker=&#39;*&#39;, c=&#39;c&#39;) . anim_adam = animation.FuncAnimation(fig, step_adam, frames=epochs, interval=(1/fps)*1000, repeat=False) . anim_adam.save(&#39;adam.mp4&#39;, writer=writer) . Video(&quot;../images/optimization_algos/adam.mp4&quot;, embed=True) . Your browser does not support the video tag. Results . We see that all the algorithms find the minimas but take significatnly different paths. While Vanilla gradient descent and gradient descent with momentum find the minima faster compared to RMSprop and Adam here for the same learning rate, studies have proven Adam to be more stable and this ability allows to use higher learning rates as compared to the same learning rates used here. .",
            "url": "https://logicatcore.github.io/scratchpad/machine%20learning/jupyter/2020/10/28/Machine-Learning-Optimization-Algorithms.html",
            "relUrl": "/machine%20learning/jupyter/2020/10/28/Machine-Learning-Optimization-Algorithms.html",
            "date": " • Oct 28, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Google kickstart Mural coding question(2018 RoundH)",
            "content": "Importance of reusing the results (Dynamic programming) . Problem statement: Summary . . There are N sections on a wall and you can paint only one of the sections in a day, the next day you are allowed to paint the section which is adjacent to a painted one only. Also, everyday one section gets destroyed and the section which gets destroyed are always at the ends (adjacent to unpainted ones) . In the above figure you will see one of the many possibilities. . P# -&gt; Painted section on day # | D# -&gt; Destroyed section on day # | . Problem description . Thanh wants to paint a wonderful mural on a wall that is N sections long. Each section of the wall has a beauty score, which indicates how beautiful it will look if it is painted. Unfortunately, the wall is starting to crumble due to a recent flood, so he will need to work fast! At the beginning of each day, Thanh will paint one of the sections of the wall. On the first day, he is free to paint any section he likes. On each subsequent day, he must paint a new section that is next to a section he has already painted, since he does not want to split up the mural. At the end of each day, one section of the wall will be destroyed. It is always a section of wall that is adjacent to only one other section and is unpainted (Thanh is using a waterproof paint, so painted sections can’t be destroyed). The total beauty of Thanh’s mural will be equal to the sum of the beauty scores of the sections he has painted. Thanh would like to guarantee that, no matter how the wall is destroyed, he can still achieve a total beauty of at least B. What’s the maximum value of B for which he can make this guarantee? . Input . The first line of the input gives the number of test cases, T. T test cases follow. Each test case starts with a line containing an integer N. Then, another line follows containing a string of N digits from 0 to 9. The i-th digit represents the beauty score of the i-th section of the wall. . Output . For each test case, output one line containing Case #x: y, where x is the test case number (starting from 1) and y is the maximum beauty score that Thanh can guarantee that he can achieve, as described above. . Limits . 1 ≤ T ≤ 100. Time limit: 20 seconds per test set. Memory limit: 1 GB. . Small dataset (Test set 1 - Visible) . 2 ≤ N ≤ 100. . Large dataset (Test set 2 - Hidden) . For exactly 1 case, N = 5 × 106; for the other T - 1 cases, 2 ≤ N ≤ 100. Sample . Meaning Input Output . Cases | 4 | Case #1: 6 | . #Sections | 4 | Case #2: 14 | . Beauty scores | 1332 | Case #3: 7 | . #Sections | 4 | Case #4: 31 | . Beauty scores | 9583 |   | . #Sections | 3 |   | . Beauty scores | 616 |   | . #Sections | 10 |   | . Beauty scores | 1029384756 |   | . In the first sample case, Thanh can get a total beauty of 6, no matter how the wall is destroyed. On the first day, he can paint either section of wall with beauty score 3. At the end of the day, either the 1st section or the 4th section will be destroyed, but it does not matter which one. On the second day, he can paint the other section with beauty score 3. . | In the second sample case, Thanh can get a total beauty of 14, by painting the leftmost section of wall (with beauty score 9). The only section of wall that can be destroyed is the rightmost one, since the leftmost one is painted. On the second day, he can paint the second leftmost section with beauty score 5. Then the last unpainted section of wall on the right is destroyed. Note that on the second day, Thanh cannot choose to paint the third section of wall (with beauty score 8), since it is not adjacent to any other painted sections. . | In the third sample case, Thanh can get a total beauty of 7. He begins by painting the section in the middle (with beauty score 1). Whichever section is destroyed at the end of the day, he can paint the remaining wall at the start of the second day. . | . Solution . . Looking at the problem and the sample solutions, it is clear that the painted sections are always contiguous(next to each other as chain link) and the length of the painted sections is ceil(N/2). . The solution to the problem is quite simple in it’s own worth but the challenge is to come up with a efficient solution to solve for large number of sections!! The solution to the problem is max of the rolling sum of roll length ceil(N/2) . If you are familiar with pandas library, the solution is a one line of code if we have all the beauty scores of the wall sections in a pandas Series- . import pandas as pd beauty_scores = pd.read_csv(&#39;input/path/to/file&#39;, delimiter=&#39; &#39;) result = pd.beauty_scores.rolling(math.ceil(N/2)).sum().max() . Read the data . . wall_sections = [] beauty_scores = [] with open(&#39;../inputs/mural_2018_H.txt&#39;) as file: cases = int(file.readline().rstrip()) for case in range(cases): wall_sections.append(int(file.readline().rstrip())) beauty_scores.append(list(map(int, list(file.readline().rstrip())))) . Solve the test case one by one . . We first calculate the roll length and then calculate the roll sums of the beauty scores . def solve_a(sections, bs): if sections % 2 == 0: roll = sections // 2 roll_sums = [sum(bs[i:i+roll]) for i in range(sections - roll + 1)] else: roll = sections // 2 + 1 roll_sums = [sum(bs[i:i+roll+1]) for i in range(sections - roll)] return max(roll_sums) for case in range(cases): result = solve(wall_sections[case], beauty_scores[case]) print(&quot;Case #{}: {}&quot;.format(case + 1, result)) . Let us have a look at the number of operations involved- . roll_windows = N - roll_length | summations = (roll_windows) * roll_length | comparisons = roll_windows | . i.e., O(roll_windows + summations + comparisons) Note: The scales are in log . Improved solution, making use of previous results . Based on the operations breakdown we have seen just now, I see that a substantial number of summations can be avoided by utilizing the concept that every successive roll window overlaps the previous roll window except one element/beauty score To save on computations, we just have to add the beauty score of the new section and subtract which we do not want anymore. . Let us have a look at the number of operations involved- . roll_windows = N - roll_length | summations = (roll_windows) * 2 | comparisons = roll_windows | . i.e., O(roll_windows + summations + comparisons) . Based on the graphs it is clear that we see an improvement from O(10^(2log(N))) to O(10^log(N)) . def solve_b(sections, bs): if sections % 2 == 0: roll = sections // 2 tmp = sum(bs[:roll]) max_value = tmp for i in range(1, sections - roll + 1): tmp = tmp + bs[i+roll-1] - bs[i-1] if max_value &lt; tmp: max_value = tmp return max_value else: roll = sections // 2 + 1 tmp = sum(bs[:roll]) max_value = tmp for i in range(1, sections - roll + 1): tmp = tmp + bs[i + roll - 1] - bs[i - 1] if max_value &lt; tmp: max_value = tmp return max_value . Time comparisons . . . Slow(time in seconds) Fast(time in seconds) Improvement factor (times x) Wall sections . 7.91e-05 | 6.48e-05 | 1.22x | 4 | . 4.24e-05 | 3.95e-05 | 1.07x | 4 | . 4.36e-05 | 4.31e-05 | 1.01x | 3 | . 4.38e-05 | 9.08e-05 | 0.48x | 10 | . 0.00121 | 0.00146 | 0.83x | 500 | . 0.0784 | 0.0158 | 4.94x | 5000 | . 6.80 | 0.15 | 44.55x | 50000 | . 712.75 | 1.49 | 478.12x | 500000 | . Try it out . . If you feel like working out or if you have a much simpler and faster approach to solving this problem, I would like to see and learn!! . Here is the link to Test input and the test results if you want to cross check . Case #1: 6 Case #2: 14 Case #3: 7 Case #4: 31 Case #5: 1012 Case #6: 10129 Case #7: 100501 Case #8: 1001276 .",
            "url": "https://logicatcore.github.io/scratchpad/2020/09/10/Google-kickstart-Mural-coding-question-2018-round-H.html",
            "relUrl": "/2020/09/10/Google-kickstart-Mural-coding-question-2018-round-H.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Topology constrained search",
            "content": "Topology constrained search . . Objective . . . To find the 2000th such number in the spiral arrangement of hexagons as seen above, which can divide the product of 6 neighbouring numbers perfectly i.e, the number in the central hexagon should be a factor of the product of the adjacent 6 numbers. . (20 * 37 * 19 * 2 * 9 * 21) / 8 = 664335 (20 * 37 * 19 * 2 * 9 * 21) % 8 = 0 . Logic behind the solution . . As there seems to be no pattern among the numbers distribution around any given hexagon which can be leveraged to find the neighbouring numbers of every hexagon. We resort to reproduce the hexagonal arrangement of numbers as per the problem statement in order to actually determine the neighbouring 6 numbers of any number we are interested in. . . | The next important step is to identify the 6 neighbouring numbers of all the numbers based on the euclidean distance of nearest 6 numbers . . | Next, we start to check if the center number is a factor of the product of the 6 neighbouring numbers. Trying to actually multiply and then divide will eventually bring us to the point where a double or float64 can preceisely store the value of multiplication and hence we need to solve this problem in a smart way. My approach to solving this was based on Prime factorisation . First, we find the prime factors of the center number and the surronding numbers | If all the prime factors of the center are present in the prime factors of all the 6 neighbouring numbers. Then the center number is a factor of the 6 other numbers | | Finally, stop the program when the 2000th number meeting our criteria is found . . | .",
            "url": "https://logicatcore.github.io/scratchpad/2020/08/31/Akka-Coding-Challenge.html",
            "relUrl": "/2020/08/31/Akka-Coding-Challenge.html",
            "date": " • Aug 31, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Shortest route Dijkstra algorithm implementation",
            "content": "This area is not a drop target. Please use the scrollbar to the right to scroll the page down if the mouse scroll gesture doesn&#39;t work (scroll gesture also acts as a zoom-in and zoom-out in this blog post). . . (Click the drag the nodes to interact with the graph) The animation shows the way the Dijikstra&#39;s algorithm progresses and searches for the destination planet/target. A collection of possible routes from one node are coloured with the same color and finally when the shortest route to the destination planet is found, the found route i.e. the solution is highlighted with RED coloured thick lines. . Click to animate . Betrandt AG&#39;s coding challenge . I didn&#39;t actually happen to randomly start working on this blog post. This blog post is inspired by my participation in the coding challenge organised by Betrandt AG. The entire details of the coding challenge are available here https://www.get-in-it.de/magazin/events/challenges/review-coding-in-the-galaxy . Dijikstra’s algorithm . Dijkstra’s algorithm (or Dijkstra’s Shortest Path First algorithm, SPF algorithm) is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks. It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later. . This particular coding challenge deals with a single source and single destination. The algorithm states to visit the child planets in the order of least cost and keep updating the path when a route with lower cost is found. . Example: . . Start: at node 1 . Iter: 1 . To vist: [2, 3, 4] in order (children of node 1) | Parent -&gt; [childs] | 2 -&gt; [3, 5] | 3 -&gt; [4, 5, 6] | 4 -&gt; [6] | . iter: 2 . To vist: [[3, 5], [4, 6, 5], [6]] in order (children of unvisited nodes only to avoid repetition) . | Cost of reaching 3 via 2 is 4+1 which is less than 1 -&gt; 3, so update the cost and path to reach 3 . | Cost of reaching 5 via 2 is 4+7 and this is first time we are visiting the node, so store the cost and path to reach 5 . | Cost of reaching 4 via 3 is 4+1+2 and this is less than 1 -&gt; 4, so update the path and cost to reach 4 . | Cost of reaching 6 via 3 is 4+1+4 and this is first time we are visiting the node, so store the cost and path to reach 6 . | Cost of reaching 5 via 3 is now 4+1+5 which is less than 1 -&gt; 3 -&gt; 5 because we have updated the path to reach 3 already and cost of paths 1 -&gt; 2 -&gt; 3 -&gt; 5(new) &lt; 1 -&gt; 2 -&gt; 5(existing path known), so update the cost and path to reach 5 . | Cost of reaching 6 via 4 is 4+1+2+5 and this is more than 1 -&gt; 2 -&gt; 3 -&gt; 6, so do not update the cost and path to reach 6 . | . iter:3 . To visit:[[7], [5, 7]] in order (children of unvisited nodes only to avoid repetition) | Cost of reaching 7 via 5 is 4+1+5+6 and this is first time we are visiting the node, so store the cost and path to reach 7 | Cost of reaching 5 via 6 is 4+1+4+1 and this is same as 1 -&gt; 2 -&gt; 3 -&gt; 5, so do not update the cost and path to reach 5 | Cost of reaching 7 via 6 is 4+1+4+8 and this is more than 1 -&gt; 2 -&gt; 3 -&gt; 5 -&gt; 7, so do not update the cost and path to reach 7 | . Task description . Find the only route from planet Erde to b3-r7-r4nd7 i.e, node 18 to node 246 among 1000 planets and 1500 routes possible in a bidirectional graph/map which allows moving from one planet to another with every route being associated with a cost value. . Working of code . -&gt; Works based on Dijkstra’s algorithm of single source and single destination . -&gt; Planets are visited based on least cost basis. The sub planets are recursively visited after one complete sweep again in least cost basis. . -&gt; Relaxation, current cost, current node, actual path of every planet is kept track in a matrix . -&gt; Execution stops when we reach our destination i.e, planet 246 or the planet named b3-r7-r4nd7 . Result . Path to the destination planet is: [ 18 810 595 132 519 71 432 246] Cost to reach the destination planet is: 2.995687895999458 . {&quot;source&quot;:18,&quot;target&quot;:810,&quot;cost&quot;:0.04060214221510905} {&quot;source&quot;:595,&quot;target&quot;:810,&quot;cost&quot;:0.1628038931266662} {&quot;source&quot;:132,&quot;target&quot;:595,&quot;cost&quot;:0.6331384762650787} {&quot;source&quot;:132,&quot;target&quot;:519,&quot;cost&quot;:0.6333618615566976} {&quot;source&quot;:71,&quot;target&quot;:519,&quot;cost&quot;:0.7625760415706333} {&quot;source&quot;:71,&quot;target&quot;:432,&quot;cost&quot;:0.6742157893614655} {&quot;source&quot;:246,&quot;target&quot;:432,&quot;cost&quot;:0.08898969190380779} . JSON data . Summary . In total there are 1000 Nodes and 1500 bidirectional paths . Every node has the following properties. . Original provided json . &quot;nodes&quot;: [{&quot;label&quot;:&quot;node_0&quot;}] &quot;edges&quot;: [{&quot;source&quot;:343,&quot;target&quot;:801,&quot;cost&quot;:0.8117216039041273}] . Modified json to visualise with sigma . &quot;nodes&quot;: [{&quot;color&quot;: &quot;#000000&quot;, &quot;label&quot;: &quot;0&quot;, &quot;y&quot;: -2.3181617858307746, &quot;x&quot;: 1.2953878183376322, &quot;id&quot;: &quot;0&quot;, &quot;size&quot;: 0.02775471971630339} &quot;edges&quot;: [{&quot;source&quot;:343,&quot;target&quot;:801,&quot;cost&quot;:0.8117216039041273}] . Data types conversion table between JSON &lt;-&gt; Python . | ++-+ | | JSON | Python | | +===============+===================+ | | object | dict | | ++-+ | | array | list | | ++-+ | | string | unicode | | ++-+ | | number (int) | int, long | | ++-+ | | number (real) | float | | ++-+ | | true | True | | ++-+ | | false | False | | ++-+ | +-++ | | Python | JSON | | +===================+===============+ | | dict | object | | +-++ | | list, tuple | array | | +-++ | | str, unicode | string | | +-++ | | int, long, float | number | | +-++ | | True | true | | +-++ | | False | false | | +-++ | | None | null | | +-++ .",
            "url": "https://logicatcore.github.io/scratchpad/2020/08/15/Finding-shortest-route-using-Dijkstra-algorithm.html",
            "relUrl": "/2020/08/15/Finding-shortest-route-using-Dijkstra-algorithm.html",
            "date": " • Aug 15, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Finding the coordinates of non-zero pixels in sparse images/matrices",
            "content": "Sparse images/matrices are those in which the contained useful information is less compared to total space being occupied. . To begin with, we will look at an example image/matrix, the output we need and the main take aways from this post. . . Task: To determine the (row, column) values of all the non zero pixels in a matrix or an image. Typical example would be text in a image. If you are familiar with the well known MNIST Handwritten digits dataset, that could be another good example of a sparse image . . The threshold need not be zero and can be any arbitrary value of interest Example images that we will be working with . . . . . We will be going through two approaches in this short tutorial and also see how the methods compare in execution time . Method 1: The traditional and the first approach that comes to mind through for loops . Method 2: We can leverage the broadcasting properties of numpy and find a work around to reach the same result . Libraries used . . matplotlib | time | numpy | . Pre Prep . . First we need to create a sparse image to work with . import time import numpy as np import matplotlib.pyplot as plt # Image height and width dimensions rows = 100 columns = 100 img = np.random.rand(rows, columns) # Drawing number from uniform distribution [0,1] to avoid negative values img = img * 255 img[img &lt; 220] = 0 # this is optional and can be skipped to handle any threshold other than &#39;non zero value&#39; &amp; &#39;zero&#39; img = img.astype(np.uint8) print(f&quot;sparsity: {len(img[img != 0]) * 100 / np.cumproduct(img.shape)[-1]} %&quot;) . Method 1 . . x_coords = np.array([]) # To store column values y_coords = np.array([]) # To store row values start = time.time() for r in range(rows): for c in range(columns): if img[r][c] != 0: x_coords = np.concatenate((x_coords, np.array([c]))) y_coords = np.concatenate((y_coords, np.array([r]))) x_coords = x_coords.reshape(-1, 1) y_coords = y_coords.reshape(-1, 1) coords = np.hstack((y_coords, x_coords)) print(&quot;Finding non zero pixels coordinates with for loops took: &quot;, time.time() - start, &quot; seconds&quot;) . Method 2 . . First we create a template to go with our image dimension and make a boolean mask which we use to find the non zero pixel coordinates . coordinates_grid = np.ones((2, rows, columns), dtype=np.int16) coordinates_grid[0] = coordinates_grid[0] * np.array([range(rows)]).T coordinates_grid[1] = coordinates_grid[1] * np.array([range(rows)]) start = time.time() mask = img != 0 non_zero_coords = np.hstack((coordinates_grid[0][mask].reshape(-1, 1), coordinates_grid[1][mask].reshape(-1, 1))) print(&quot;Finding non zero pixels coordinates using broadcasting took: &quot;, time.time() - start, &quot; seconds&quot;) # print(&quot;Coordinates of the non zero pixels are: n&quot;, non_zero_coords) plt.imshow(img) plt.show() . Results . . sai@sai:~/****/scripts$ python coordinates.py 10 10 information: 13.0 % Finding non zero pixels coordinates with for loops took: 0.0003330707550048828 seconds Finding non zero pixels coordinates using broadcasting took: 3.4809112548828125e-05 seconds sai@sai:~/****/scripts$ python coordinates.py 100 100 information: 13.43 % Finding non zero pixels coordinates with for loops took: 0.024660587310791016 seconds Finding non zero pixels coordinates using broadcasting took: 0.00010442733764648438 seconds sai@sai:~/****/scripts$ python coordinates.py 1000 1000 information: 13.7047 % Finding non zero pixels coordinates with for loops took: 8.874347448348999 seconds Finding non zero pixels coordinates using broadcasting took: 0.007306575775146484 seconds . Conclusions . . It is clear that the execution times differ significantly and the benefits of vectorization becomes more dominant as the input data grows. .",
            "url": "https://logicatcore.github.io/scratchpad/2020/08/13/sparse-image-coordinates.html",
            "relUrl": "/2020/08/13/sparse-image-coordinates.html",
            "date": " • Aug 13, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About me",
          "content": "Intro . My name is Sai Sharath Kakubal, I am from India and am currently pursuing my Masters course at Technische Hochschule Ingolstadt, Germany in International Automotive Engineering with a specialisation in Vehicle Electronics. . Interests and skills . Having pursued Mechanical Engineering in India and having been part of designing and building a Formula Student Race car during my Bachelor’s in a student team and having gotten opportunites to work as an Intern in a couple of companies has allowed me to hone my skills and build upon them progressively. My interests and skills are spread across a wide spectrum, and I especially like good presentation and like to learn new tools to complete any task in an efficient and an elegant way. . I am also passionate about Machine Learning and A.I fields and keep myself upto date with the latest advancements in these fields. . Programming languages that I have worked with . Python | C++ | Matlab | Java | C | .",
          "url": "https://logicatcore.github.io/scratchpad/_pages/about.html",
          "relUrl": "/_pages/about.html",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
  

  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://logicatcore.github.io/scratchpad/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}